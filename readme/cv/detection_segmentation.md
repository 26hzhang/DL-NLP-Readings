# Object Detection and Semantic Segmentation

## Object Detection
- [2017 CVPR] **Feature Pyramid Networks for Object Detection**, [[paper]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Lin_Feature_Pyramid_Networks_CVPR_2017_paper.pdf), [[bibtex]](/Bibtex/Feature%20Pyramid%20Networks%20for%20Object%20Detection.bib), sources: [[unsky/FPN]](https://github.com/unsky/FPN), [[DetectionTeamUCAS/FPN_Tensorflow]](https://github.com/DetectionTeamUCAS/FPN_Tensorflow), [[yangxue0827/FPN_Tensorflow]](https://github.com/yangxue0827/FPN_Tensorflow).
- [2017 ICCV] **Mask R-CNN**, [[paper]](https://arxiv.org/pdf/1703.06870.pdf), [[bibtex]](/Bibtex/Mask%20R-CNN.bib), [[tutorial]](http://kaiminghe.com/iccv17tutorial/maskrcnn_iccv2017_tutorial_kaiminghe.pdf), [[video]](https://www.youtube.com/watch?v=2TikTv6PWDw), sources: [[matterport/Mask_RCNN]](https://github.com/matterport/Mask_RCNN), [[CharlesShang/FastMaskRCNN]](https://github.com/CharlesShang/FastMaskRCNN), [[facebookresearch/Detectron]](https://github.com/facebookresearch/Detectron).
- [2017 ICCV] **Focal Loss for Dense Object Detection**, [[paper]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Lin_Focal_Loss_for_ICCV_2017_paper.pdf), [[bibtex]](/Bibtex/Focal%20Loss%20for%20Dense%20Object%20Detection.bib), sources: [[unsky/focal-loss]](https://github.com/unsky/focal-loss), [[ailias/Focal-Loss-implement-on-Tensorflow]](https://github.com/ailias/Focal-Loss-implement-on-Tensorflow).
- [2017 ICCV] **Deformable Convolutional Networks**, [[paper]](https://openaccess.thecvf.com/content_ICCV_2017/papers/Dai_Deformable_Convolutional_Networks_ICCV_2017_paper.pdf), [[bibtex]](/Bibtex/Deformable%20Convolutional%20Networks.bib), sources: [[msracver/Deformable-ConvNets]](https://github.com/msracver/Deformable-ConvNets).
- [2018 ECCV] **DOCK: Detecting Objects by Transferring Common-sense Knowledge**, [[paper]](http://openaccess.thecvf.com/content_ECCV_2018/papers/Krishna_Kumar_Singh_Transferring_Common-Sense_Knowledge_ECCV_2018_paper.pdf), [[bibtex]](/Bibtex/DOCK%20-%20Detecting%20Objects%20by%20transferring%20Common-sense%20Knowledge.bib), sources: [[kkanshul/dock]](https://github.com/kkanshul/dock).
- [2018 CVPR] **Non-local Neural Networks**, [[paper]](https://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.pdf), [[bibtex]](/Bibtex/Non-local%20Neural%20Networks.bib), sources: [[facebookresearch/video-nonlocal-net]](https://github.com/facebookresearch/video-nonlocal-net).
- [2018 CVPR] **Squeeze-and-Excitation Networks**, [[paper]](https://zpascal.net/cvpr2018/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.pdf), [[bibtex]](/Bibtex/Squeeze-and-Excitation%20Networks.bib), sources: [[hujie-frank/SENet]](https://github.com/hujie-frank/SENet).
- [2019 NeurIPS] **Stand-Alone Self-Attention in Vision Models**, [[paper]](https://papers.nips.cc/paper/2019/file/3416a75f4cea9109507cacd8e2f2aefc-Paper.pdf), [[bibtex]](/Bibtex/Stand-Alone%20Self-Attention%20in%20Vision%20Models.bib), sources: [[leaderj1001/Stand-Alone-Self-Attention]](https://github.com/leaderj1001/Stand-Alone-Self-Attention), [[google-research/standalone_self_attention_in_vision_models]](https://github.com/google-research/google-research/tree/master/standalone_self_attention_in_vision_models).
- [2020 ECCV] **End-to-End Object Detection with Transformer**, [[paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123460205.pdf), [[bibtex]](/Bibtex/End-to-End%20Object%20Detection%20with%20Transformer.bib), sources: [[facebookresearch/detr]](https://github.com/facebookresearch/detr).
- [2020 CVPR] **Dynamic Convolution: Attention over Convolution Kernels**, [[paper]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_Dynamic_Convolution_Attention_Over_Convolution_Kernels_CVPR_2020_paper.pdf), [[bibtex]](/Bibtex/Dynamic%20Convolution%20-%20Attention%20over%20Convolution%20Kernels.bib), sources: [[kaijieshi7/Dynamic-convolution-Pytorch]](https://github.com/kaijieshi7/Dynamic-convolution-Pytorch).
- [2020 ArXiv] **ResNeSt: Split-Attention Networks**, [[paper]](https://arxiv.org/pdf/2004.08955.pdf), [[bibtex]](/Bibtex/ResNeSt%20-%20Split-Attention%20Networks.bib), sources: [[zhanghang1989/ResNeSt]](https://github.com/zhanghang1989/ResNeSt).

## Semantic Segmentation
- [2015 IPMI] **Predicting Semantic Descriptions from Medical Images with Convolutional Neural Networks**, [[paper]](/Documents/Papers/Predicting%20Semantic%20Descriptions%20from%20Medical%20Images%20with%20Convolutional%20Neural%20Networks.pdf), [[bibtex]](/Bibtex/Predicting%20Semantic%20Descriptions%20from%20Medical%20Images%20with%20Convolutional%20Neural%20Networks.bib).
- [2017 CVPR] **PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation**, [[paper]](https://arxiv.org/pdf/1612.00593.pdf), [[bibtex]](/Bibtex/PointNet.bib) sources: [[charlesq34/pointnet]](https://github.com/charlesq34/pointnet).
- [2017 ICCV] **Deformable Convolutional Networks**, [[paper]](https://openaccess.thecvf.com/content_ICCV_2017/papers/Dai_Deformable_Convolutional_Networks_ICCV_2017_paper.pdf), [[bibtex]](/Bibtex/Deformable%20Convolutional%20Networks.bib), sources: [[msracver/Deformable-ConvNets]](https://github.com/msracver/Deformable-ConvNets).
- [2018 ICML] **Attention-based Deep Multiple Instance Learning**, [[paper]](https://arxiv.org/pdf/1802.04712.pdf), [[bibtex]](/Bibtex/Attention-based%20Deep%20Multiple%20Instance%20Learning.bib), sources: [[AMLab-Amsterdam/AttentionDeepMIL]](https://github.com/AMLab-Amsterdam/AttentionDeepMIL).
- [2019 CVPR] **Cross-Modal Self-Attention Network for Referring Image Segmentation**, [[paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Ye_Cross-Modal_Self-Attention_Network_for_Referring_Image_Segmentation_CVPR_2019_paper.pdf), [[bibtex]](/Bibtex/Cross-Modal%20Self-Attention%20Network%20for%20Referring%20Image%20Segmentation.bib), sources: [[lwye/CMSA-Net]](https://github.com/lwye/CMSA-Net).
- [2020 ArXiv] **ResNeSt: Split-Attention Networks**, [[paper]](https://arxiv.org/pdf/2004.08955.pdf), [[bibtex]](/Bibtex/ResNeSt%20-%20Split-Attention%20Networks.bib), sources: [[zhanghang1989/ResNeSt]](https://github.com/zhanghang1989/ResNeSt).