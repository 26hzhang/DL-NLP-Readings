# Machine Comprehension, QA, NLU, NLSM

## Dataset
- [2013 EMNLP] **MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text**, [[paper]](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/MCTest_EMNLP2013.pdf), [[homepage]](https://mattr1.github.io/mctest/), source: [[mcobzarenco/mctest]](https://github.com/mcobzarenco/mctest).
- [2015 NIPS] **CNN/DailyMail: Teaching Machines to Read and Comprehend**, [[paper]](https://papers.nips.cc/paper/5945-teaching-machines-to-read-and-comprehend.pdf), [[homepage]](https://cs.nyu.edu/~kcho/DMQA/), sources: [[thomasmesnard/DeepMind-Teaching-Machines-to-Read-and-Comprehend]](https://github.com/thomasmesnard/DeepMind-Teaching-Machines-to-Read-and-Comprehend).
- [2016 EMNLP] **SQuAD 100,000+ Questions for Machine Comprehension of Text**, [[paper]](https://arxiv.org/abs/1606.05250.pdf), [[homepage]](https://rajpurkar.github.io/SQuAD-explorer/).
- [2016 ICLR] **bAbI: Towards AI-Complete Question Answering: a Set of Prerequisite Toy Tasks**, [[paper]](https://arxiv.org/abs/1502.05698.pdf), [[homepage]](https://research.fb.com/downloads/babi/), sources: [[facebook/bAbI-tasks]](https://github.com/facebook/bAbI-tasks).
- [2017 EMNLP] **World Knowledge for Reading Comprehension: Rare Entity Prediction with Hierarchical LSTMs Using External Descriptions**, [[paper]](http://aclweb.org/anthology/D17-1086), [[homepage]](http://dataset.cs.mcgill.ca/downloads/rare_entity_dataset.html).
- [2017 EMNLP] **RACE: Large-scale ReAding Comprehension Dataset From Examinations**, [[paper]](https://arxiv.org/pdf/1704.04683.pdf), [[homepage]](http://www.cs.cmu.edu/~glai1/data/race/), sources: [[qizhex/RACE_AR_baselines]](https://github.com/qizhex/RACE_AR_baselines).
- [2017 ACL] **TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension**, [[paper]](https://arxiv.org/abs/1705.03551.pdf), [[homepage]](http://nlp.cs.washington.edu/triviaqa/), sources: [[mandarjoshi90/triviaqa]](https://github.com/mandarjoshi90/triviaqa).
- [2017 ArXiv] **QAngaroo: Constructing Datasets for Multi-hop Reading Comprehension Across Documents**, [[paper]](https://arxiv.org/pdf/1710.06481.pdf), [[homepage]](http://qangaroo.cs.ucl.ac.uk), 
- [2018 ICLR] **CLOTH: Large-scale Cloze Test Dataset Designed by Teachers**, [[paper]](https://arxiv.org/abs/1711.03225.pdf), [[homepage]](http://www.qizhexie.com), sources: [[qizhex/Large-scale-Cloze-Test-Dataset-Designed-by-Teachers]](https://github.com/qizhex/Large-scale-Cloze-Test-Dataset-Designed-by-Teachers).
- [2018 NAACL] **MultiRC: Looking Beyond the Surface -- A Challenge Set for Reading Comprehension over Multiple Sentences**, [[paper]](http://cogcomp.org/papers/2018-MultiRC-NAACL.pdf), [[homepage]](http://cogcomp.org/multirc/), sources: [[CogComp/multirc]](https://github.com/CogComp/multirc/).

## Machine Comprehension
- [2014 NIPS] **Deep Learning for Answer Sentence Selection**, [[paper]](https://arxiv.org/pdf/1412.1632.pdf), sources: [[brmson/Sentence-selection]](https://github.com/brmson/Sentence-selection).
- [2015 NIPS] **Pointer Networks**, [[paper]](https://arxiv.org/pdf/1506.03134.pdf), [[blog]](http://fastml.com/introduction-to-pointer-networks/), sources: [[devsisters/pointer-network-tensorflow]](https://github.com/devsisters/pointer-network-tensorflow), [[https://github.com/ikostrikov/TensorFlow-Pointer-Networks]](https://github.com/ikostrikov/TensorFlow-Pointer-Networks), [[keon/pointer-networks]](https://github.com/keon/pointer-networks), [[pemami4911/neural-combinatorial-rl-pytorch]](https://github.com/pemami4911/neural-combinatorial-rl-pytorch), [[shiretzet/PointerNet]](https://github.com/shiretzet/PointerNet).
- [2016 ICLR] **LSTM-based Deep Learning Models for Non-factoid Answer Selection**, [[paper]](https://arxiv.org/abs/1511.04108.pdf), sources: [[Alan-Lee123/answer-selection]](https://github.com/Alan-Lee123/answer-selection), [[tambetm/allenAI]](https://github.com/tambetm/allenAI).
- [2016 ACL] **A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task**, [[paper]](https://arxiv.org/abs/1606.02858.pdf), sources: [[danqi/rc-cnn-dailymail]](https://github.com/danqi/rc-cnn-dailymail).
- [2017 ICLR] **Query-Reduction Networks for Question Answering**, [[paper]](https://arxiv.org/abs/1606.04582.pdf), [[homepage]](http://uwnlp.github.io/qrn/), sources: [[uwnlp/qrn]](https://github.com/uwnlp/qrn).
- [2017 ICLR] **Bi-Directional Attention Flow for Machine Comprehension**, [[paper]](https://arxiv.org/abs/1611.01603.pdf), [[homepage]](https://allenai.github.io/bi-att-flow/), [[demo]](http://allgood.cs.washington.edu:1995), sources: [[allenai/bi-att-flow]](https://github.com/allenai/bi-att-flow).
- [2017 ACL] **Reading Wikipedia to Answer Open-Domain Questions**, [[paper]](https://arxiv.org/abs/1704.00051.pdf), sources: [[facebookresearch/DrQA]](https://github.com/facebookresearch/DrQA), [[hitvoice/DrQA]](https://github.com/hitvoice/DrQA).
- [2017 ACL] **R-Net: Machine Reading Comprehension with Self-matching Networks**, [[paper]](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf), [[blog]](http://yerevann.github.io/2017/08/25/challenges-of-reproducing-r-net-neural-network-using-keras/), sources: [[HKUST-KnowComp/R-Net]](https://github.com/HKUST-KnowComp/R-Net), [[YerevaNN/R-NET-in-Keras]](https://github.com/YerevaNN/R-NET-in-Keras), [[minsangkim142/R-net]](https://github.com/minsangkim142/R-net).
- [2017 ArXiv] **Simple and Effective Multi-Paragraph Reading Comprehension**, [[paper]](https://arxiv.org/abs/1710.10723.pdf), sources: [[allenai/document-qa]](https://github.com/allenai/document-qa).
- [2017 CoNLL] **Making Neural QA as Simple as Possible but not Simpler**, [[paper]](https://arxiv.org/abs/1703.04816.pdf), [[homepage]](https://dirkweissenborn.github.io/publications.html), [[github-page]](https://github.com/georgwiese), sources: [[georgwiese/biomedical-qa]](https://github.com/georgwiese/biomedical-qa).
- [2017 ACL] **An End-to-End Model for Question Answering over Knowledge Base with Cross-Attention Combining Global Knowledge**, [[paper]](https://arxiv.org/abs/1606.00979.pdf), [[homepage]](http://www.nlpr.ia.ac.cn/cip/~liukang/index.html), [[blog]](http://blog.csdn.net/LAW_130625/article/details/78484866).
- [2017 ArXiv] **Dynamic Integration of Background Knowledge in Neural NLU Systems**, [[paper]](https://arxiv.org/abs/1706.02596.pdf), [[homepage]](https://dirkweissenborn.github.io/publications.html).
- [2017 EMNLP] **Two-Stage Synthesis Networks for Transfer Learning in Machine Comprehension**, [[paper]](https://arxiv.org/abs/1706.09789.pdf), sources: [[davidgolub/QuestionGeneration]](https://github.com/davidgolub/QuestionGeneration).
- [2017 ACL] **Improved Neural Relation Detection for Knowledge Base Question Answering**, [[paper]](https://arxiv.org/abs/1704.06194.pdf).
- [2017 ACL] **Attention-over-Attention Neural Networks for Reading Comprehension**, [[paper]](https://arxiv.org/abs/1607.04423.pdf), sources: [[OlavHN/attention-over-attention]](https://github.com/OlavHN/attention-over-attention), [[marshmelloX/attention-over-attention]](https://github.com/marshmelloX/attention-over-attention).
- [2018 ICLR] **MaskGAN: Better Text Generation via Filling in the `______`**, [[paper]](https://arxiv.org/abs/1801.07736.pdf).
- [2018 AAAI] **Multi-attention Recurrent Network for Human Communication Comprehension**, [[paper]](https://arxiv.org/abs/1802.00923.pdf).
- [2018 ArXiv] **An Attention-Based Word-Level Interaction Model: Relation Detection for Knowledge Base Question Answering**, [[paper]](https://arxiv.org/abs/1801.09893.pdf).
- [2018 SemEval] **Yuanfudao at SemEval-2018 Task 11: Three-way Attention and Relational Knowledge for Commonsense Machine Comprehension**, [[paper]](https://arxiv.org/pdf/1803.00191.pdf), sources: [[intfloat/commonsense-rc]](https://github.com/intfloat/commonsense-rc).
- [2018 ICLR] **FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension**, [[paper]](https://arxiv.org/abs/1711.07341), sources: [[exe1023/FusionNet]](https://github.com/exe1023/FusionNet), [[momohuang/FusionNet-NLI]](https://github.com/momohuang/FusionNet-NLI).
- [2018 NAACL] **Contextualized Word Representations for Reading Comprehension**, [[paper]](https://arxiv.org/pdf/1712.03609.pdf), sources: [[shimisalant/CWR]](https://github.com/shimisalant/CWR).
- [2018 ICLR] **QANet: Combing Local Convolution with Global Self-Attention for Reading Comprehension**, [[paper]](https://arxiv.org/pdf/1804.09541.pdf), sources: [[hengruo/QANet-pytorch]](https://github.com/hengruo/QANet-pytorch), [[NLPLearn/QANet]](https://github.com/NLPLearn/QANet).

## Memory Networks
- [2015 ICLR] **Memory Networks**, [[paper]](https://arxiv.org/abs/1410.3916.pdf), sources: [[facebook/MemNN]](https://github.com/facebook/MemNN).
- [2015 NIPS] **End-To-End Memory Networks**, [[paper]](https://arxiv.org/abs/1503.08895.pdf), sources: [[facebook/MemNN]](https://github.com/facebook/MemNN), [[seominjoon/memnn-tensorflow]](https://github.com/seominjoon/memnn-tensorflow), [[domluna/memn2n]](https://github.com/domluna/memn2n), [[carpedm20/MemN2N-tensorflow]](https://github.com/carpedm20/MemN2N-tensorflow).
- [2016 ICML] **Dynamic Memory Networks for Visual and Textual Question Answering**, [[paper]](https://arxiv.org/abs/1603.01417), [[blog]](https://yerevann.github.io/2016/02/05/implementing-dynamic-memory-networks/), sources: [[therne/dmn-tensorflow]](https://github.com/therne/dmn-tensorflow), [[barronalex/Dynamic-Memory-Networks-in-TensorFlow]](https://github.com/barronalex/Dynamic-Memory-Networks-in-TensorFlow), [[ethancaballero/Improved-Dynamic-Memory-Networks-DMN-plus]](https://github.com/ethancaballero/Improved-Dynamic-Memory-Networks-DMN-plus), [[dandelin/Dynamic-memory-networks-plus-Pytorch]](https://github.com/dandelin/Dynamic-memory-networks-plus-Pytorch), [[DeepRNN/visual_question_answering]](https://github.com/DeepRNN/visual_question_answering).
- [2016 ICML] **Ask Me Anything: Dynamic Memory Networks for Natural Language Processing**, [[paper]](https://arxiv.org/abs/1506.07285), sources: [[DongjunLee/dmn-tensorflow]](https://github.com/DongjunLee/dmn-tensorflow).

## Modified LSTM/GRU for Machine Comprehension
- [2016 EMNLP] **Long Short-Term Memory-Networks for Machine Reading**, [[paper]](https://arxiv.org/pdf/1601.06733.pdf), sources: [[cheng6076/SNLI-attention]](https://github.com/cheng6076/SNLI-attention), [[vsitzmann/snli-attention-tensorflow]](https://github.com/vsitzmann/snli-attention-tensorflow).
- [2017 ACL] **Learning to Skim Text**, [[paper]](http://aclweb.org/anthology/P17-1172), [[notes]](https://zhuanlan.zhihu.com/p/30555359).
- [2017 ICLR] **Variable Computation in Recurrent Neural Networks**, [[paper]](https://arxiv.org/pdf/1611.06188.pdf).
- [2017 ICLR] **Machine Comprehension Using Match-LSTM and Answer Pointer**, [[paper]](https://arxiv.org/pdf/1608.07905.pdf), sources: [[shuohangwang/SeqMatchSeq]](https://github.com/shuohangwang/SeqMatchSeq), [[MurtyShikhar/Question-Answering]](https://github.com/MurtyShikhar/Question-Answering), [[InnerPeace-Wu/reading_comprehension-cs224n]](https://github.com/InnerPeace-Wu/reading_comprehension-cs224n).
- [2018 ICLR] **Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks**, [[paper]](https://arxiv.org/pdf/1708.06834.pdf), [[homepage]](https://imatge-upc.github.io/skiprnn-2017-telecombcn/), sources: [[imatge-upc/skiprnn-2017-telecombcn]](https://github.com/imatge-upc/skiprnn-2017-telecombcn).
- [2018 ICLR] **Neural Speed Reading via Skim-RNN**, [[paper]](https://arxiv.org/pdf/1711.02085.pdf), sources: [[schelotto/Neural_Speed_Reading_via_Skim-RNN_PyTorch]](https://github.com/schelotto/Neural_Speed_Reading_via_Skim-RNN_PyTorch).

## Natural Language Sentence Matching
- [2017 IJCAI] **BiMPM: Bilateral Multi-Perspective Matching for Natural Language Sentences**, [[paper]](https://arxiv.org/pdf/1702.03814.pdf), sources: [[zhiguowang/BiMPM]](https://github.com/zhiguowang/BiMPM).