# Char/Word Embeddings, Sentence Representation and Natural Language Understanding

## Character Embeddings
- [2016 AAAI] **Character-Aware Neural Language Models**, [[paper]](https://arxiv.org/pdf/1508.06615.pdf), [[bibtex]](/Bibtex/Character-Aware%20Neural%20Language%20Models.bib), sources: [[carpedm20/lstm-char-cnn-tensorflow]](https://github.com/carpedm20/lstm-char-cnn-tensorflow), [[yoonkim/lstm-char-cnn]](https://github.com/yoonkim/lstm-char-cnn).

## Word Embeddings
- [2009 NIPS] **HLBL: A Scalable Hierarchical Distributed Language Model**, [[paper]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.205.5467&rep=rep1&type=pdf), [[bibtex]](/Bibtex/HLBL.bib), [[wenjieguan/Log-bilinear-language-models]](https://github.com/wenjieguan/Log-bilinear-language-models).
- [2010 INTERSPEECH] **Recurrent neural network based language model**, [[paper]](http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf), [[bibtex]](/Bibtex/Recurrent%20neural%20network%20based%20language%20model.bib), [[Ph.D. Thesis]](http://www.fit.vutbr.cz/~imikolov/rnnlm/thesis.pdf), [[slides]](http://www.fit.vutbr.cz/~imikolov/rnnlm/google.pdf), sources: [[mspandit/rnnlm]](https://github.com/mspandit/rnnlm).
- [2013 NIPS] **Word2Vec: Distributed Representations of Words and Phrases and their Compositionality**, [[paper]](https://arxiv.org/pdf/1310.4546.pdf), [[bibtex]](/Bibtex/Word2Vec.bib), [[word2vec explained]](https://arxiv.org/pdf/1402.3722.pdf), [[params explained]](https://arxiv.org/pdf/1411.2738.pdf), [[blog]](https://isaacchanghau.github.io/post/word2vec/), sources: [[word2vec]](https://code.google.com/archive/p/word2vec/), [[dav/word2vec]](https://github.com/dav/word2vec), [[yandex/faster-rnnlm]](https://github.com/yandex/faster-rnnlm), [[tf-word2vec]](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/word2vec), [[zake7749/word2vec-tutorial]](https://github.com/zake7749/word2vec-tutorial).
- [2013 CoNLL] **Better Word Representations with Recursive Neural Networks for Morphology**, [[paper]](https://www.aclweb.org/anthology/W13-3512.pdf), [[bibtex]](https://www.aclweb.org/anthology/W13-3512.bib).
- [2014 ACL] **Word2Vecf: Dependency-Based Word Embeddings**, [[paper]](https://www.aclweb.org/anthology/P14-2050.pdf), [[bibtex]](https://www.aclweb.org/anthology/P14-2050.bib), sources: [[Yoav Goldberg/word2vecf]](https://bitbucket.org/yoavgo/word2vecf), [[IsaacChanghau/Word2VecfJava]](https://github.com/IsaacChanghau/Word2VecfJava).
- [2014 EMNLP] **GloVe: Global Vectors for Word Representation**, [[paper]](https://nlp.stanford.edu/pubs/glove.pdf), [[bibtex]](https://www.aclweb.org/anthology/D14-1162.bib), [[homepage]](https://nlp.stanford.edu/projects/glove/), sources: [[stanfordnlp/GloVe]](https://github.com/stanfordnlp/GloVe).
- [2014 ICML] **Compositional Morphology for Word Representations and Language Modelling**, [[paper]](http://proceedings.mlr.press/v32/botha14.pdf), [[bibtex]](/Bibtex/Compositional%20Morphology%20for%20Word%20Representations%20and%20Language%20Modelling.bib), sources: [[thompsonb/comp-morph]](https://github.com/thompsonb/comp-morph), [[claravania/subword-lstm-lm]](https://github.com/claravania/subword-lstm-lm).
- [2015 ACL] **Hyperword: Improving Distributional Similarity with Lessons Learned from Word Embeddings**, [[paper]](https://www.aclweb.org/anthology/Q15-1016.pdf), [[bibtex]](https://www.aclweb.org/anthology/Q15-1016.bib), sources: [[Omer Levy/hyperwords]](https://bitbucket.org/omerlevy/hyperwords).
- [2016 NAACL] **Counter-fitting Word Vectors to Linguistic Constraints**, [[paper]](http://aclweb.org/anthology/N16-1018), [[bibtex]](/Bibtex/Counter-fitting%20Word%20Vectors%20to%20Linguistic%20Constraints.bib), sources: [[nmrksic/counter-fitting]](https://github.com/nmrksic/counter-fitting).
- [2016 ICLR] **Exploring the Limits of Language Modeling**, [[paper]](https://arxiv.org/pdf/1602.02410.pdf), [[bibtex]](/Bibtex/Exploring%20the%20Limits%20of%20Language%20Modeling.bib), [[slides]](https://www.cs.toronto.edu/~duvenaud/courses/csc2541/slides/lipnet.pdf), sources: [[tensorflow/models/lm_1b]](https://github.com/tensorflow/models/tree/master/research/lm_1b).
- [2016 CoNLL] **Context2Vec: Learning Generic Context Embedding with Bidirectional LSTM**, [[paper]](https://www.aclweb.org/anthology/K16-1006.pdf), [[bibtex]](https://www.aclweb.org/anthology/K16-1006.bib), sources: [[orenmel/context2vec]](https://github.com/orenmel/context2vec).
- [2016 IEEE Intelligent Systems] **How to Generate a Good Word Embedding?**, [[paper]](https://arxiv.org/pdf/1507.05523.pdf), [[bibtex]](/Bibtex/How%20to%20Generate%20a%20Good%20Word%20Embedding.bib), [[基于神经网络的词和文档语义向量表示方法研究]](https://arxiv.org/pdf/1611.05962.pdf), [[blog]](http://licstar.net/archives/620), sources: [[licstar/compare]](https://github.com/licstar/compare).
- [2017 ACL] **FastText: Enriching Word Vectors with Subword Information**, [[paper]](https://www.aclweb.org/anthology/Q17-1010.pdf), [[bibtex]](https://www.aclweb.org/anthology/Q17-1010.bib), sources: [[facebookresearch/fastText]](https://github.com/facebookresearch/fastText), [[salestock/fastText.py]](https://github.com/salestock/fastText.py).
- [2017 ArXiv] **Implicitly Incorporating Morphological Information into Word Embedding**, [[paper]](https://arxiv.org/pdf/1701.02481.pdf), [[bibtex]](/Bibtex/Implicitly%20Incorporating%20Morphological%20Information%20into%20Word%20Embedding.bib).
- [2017 AAAI] **Improving Word Embeddings with Convolutional Feature Learning and Subword Information**, [[paper]](https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14724/14187), [[bibtex]](/Bibtex/Improving%20Word%20Embeddings%20with%20Convolutional%20Feature%20Learning%20and%20Subword%20Information.bib), sources: [[ShelsonCao/IWE]](https://github.com/ShelsonCao/IWE).
- [2018 TACL] **Linear Algebraic Structure of Word Senses, with Applications to Polysemy**, [[paper]](https://www.aclweb.org/anthology/Q18-1034.pdf), [[bibtex]](https://www.aclweb.org/anthology/Q18-1034.bib), [[slides]](https://pdfs.semanticscholar.org/d770/5adf01fc9791337ed17dd37236129ef3a0f4.pdf), sources: [[YingyuLiang/SemanticVector]](https://github.com/YingyuLiang/SemanticVector).
- [2018 ICML] **Learning K-way D-dimensional Discrete Codes for Compact Embedding Representations**, [[paper]](https://arxiv.org/pdf/1806.09464.pdf), [[bibtex]](/Bibtex/Learning%20K-way%20D-dimensional%20Discrete%20Codes%20for%20Compact%20Embedding%20Representations.bib), [supplementary](http://web.cs.ucla.edu/~yzsun/papers/2018_icml_KDCoding_supp.pdf), sources: [[chentingpc/kdcode-lm]](https://github.com/chentingpc/kdcode-lm).
- [2018 ICLR] **Compressing Word Embeddings via Deep Compositional Code Learning**, [[paper]](https://openreview.net/pdf?id=BJRZzFlRb), [[bibtex]](/Bibtex/Compressing%20Word%20Embeddings%20via%20Deep%20Compositional%20Code%20Learning.bib), sources: [[msobroza/compositional_code_learning]](https://github.com/msobroza/compositional_code_learning).
- [2018 ACL] **Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms**, [[paper]](https://www.aclweb.org/anthology/P18-1041), [[bibtex]](/Bibtex/Baseline%20Needs%20More%20Love.bib), sources: [[dinghanshen/SWEM]](https://github.com/dinghanshen/SWEM).
- [2019 ACL] **Few-Shot Representation Learning for Out-Of-Vocabulary Words**, [[paper]](https://www.aclweb.org/anthology/P19-1402.pdf), [[bibtex]](/Bibtex/Few-Shot%20Representation%20Learning%20for%20Out-Of-Vocabulary%20Words.bib), sources: [[acbull/HiCE]](https://github.com/acbull/HiCE).
- [2019 ACL] **Towards Understanding Linear Word Analogies**, [[paper]](https://www.aclweb.org/anthology/P19-1315.pdf), [[bibtex]](https://www.aclweb.org/anthology/P19-1315.bib).

## Sentence Embedding / Representation
- [2015 NIPS] **Skip Thought Vectors**, [[paper]](https://papers.nips.cc/paper/5950-skip-thought-vectors.pdf), [[bibtex]](/Bibtex/Skip%20Thought%20Vectors.bib), sources: [[ryankiros/skip-thoughts]](https://github.com/ryankiros/skip-thoughts).
- [2017 ICLR] **A Simple But Tough-to-beat Baseline for Sentence Embeddings**, [[paper]](https://openreview.net/pdf?id=SyK00v5xx), [[bibtex]](/Bibtex/A%20Simple%20But%20Tough-to-beat%20Baseline%20for%20Sentence%20Embeddings.bib), sources: [[PrincetonML/SIF]](https://github.com/PrincetonML/SIF).
- [2017 ICLR] **A Structured Self-attentive Sentence Embedding**, [[paper]](https://arxiv.org/pdf/1703.03130.pdf), [[bibtex]](/Bibtex/A%20Structured%20Self-attentive%20Sentence%20Embedding.bib), sources: [[ExplorerFreda/Structured-Self-Attentive-Sentence-Embedding]](https://github.com/ExplorerFreda/Structured-Self-Attentive-Sentence-Embedding), [[flrngel/Self-Attentive-tensorflow]](https://github.com/flrngel/Self-Attentive-tensorflow), [[kaushalshetty/Structured-Self-Attention]](https://github.com/kaushalshetty/Structured-Self-Attention).
- [2017 EMNLP] **Supervised Learning of Universal Sentence Representations from Natural Language Inference Data**, [[paper]](http://aclweb.org/anthology/D17-1070), [[bibtex]](/Bibtex/Supervised%20Learning%20of%20Universal%20Sentence%20Representations%20from%20Natural%20Language%20Inference%20Data.bib), sources: [[facebookresearch/InferSent]](https://github.com/facebookresearch/InferSent).
- [2018 ICLR] **Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning**, [[paper]](https://openreview.net/pdf?id=B18WgG-CZ), [[bibtex]](/Bibtex/Learning%20General%20Purpose%20Distributed%20Sentence%20Representations%20via%20Large%20Scale%20Multi-task%20Learning.bib), sources: [[Maluuba/gensen]](https://github.com/Maluuba/gensen).
- [2018 ArXiv] **Universal Sentence Encoder**, [[paper]](https://arxiv.org/pdf/1803.11175.pdf), [[bibtex]](/Bibtex/Universal%20Sentence%20Encoder.bib), sources: [[TensorFlow Hub/universal-sentence-encoder]](https://tfhub.dev/google/universal-sentence-encoder/1), [[helloeve/universal-sentence-encoder-fine-tune]](https://github.com/helloeve/universal-sentence-encoder-fine-tune).
- [2018 ArXiv] **Evaluation of Sentence Embeddings in Downstream and Linguistic Probing Tasks**, [[paper]](https://arxiv.org/pdf/1806.06259.pdf), [[bibtex]](/Bibtex/Evaluation%20of%20sentence%20embeddings%20in%20downstream%20and%20linguistic%20probing%20tasks.bib).
- [2018 EMNLP] **XNLI: Evaluating Cross-lingual Sentence Representations**, [[paper]](http://aclweb.org/anthology/D18-1269), [[bibtex]](/Bibtex/XNLI%20-%20Evaluating%20Cross-lingual%20Sentence%20Representations.bib), sources: [[facebookresearch/XNLI]](https://github.com/facebookresearch/XNLI).
- [2018 EMNLP] **Dynamic Meta-Embeddings for Improved Sentence Representations**, [[paper]](http://aclweb.org/anthology/D18-1176), [[bibtex]](/Bibtex/Dynamic%20Meta-Embeddings%20for%20Improved%20Sentence%20Representations.bib), sources: [[facebookresearch/DME]](https://github.com/facebookresearch/DME).
- [2018 ICLR] **An Efficient Framework for Learning Sentence Representations**, [[paper]](https://openreview.net/pdf?id=rJvJXZb0W), [[bibtex]](/Bibtex/An%20Efficient%20Framework%20for%20Learning%20Sentence%20Representations.bib), sources: [[lajanugen/S2V]](https://github.com/lajanugen/S2V), [[mhiro2/quick-thoughts]](https://github.com/mhiro2/quick-thoughts).
- [2018 ACL] **Sentence-State LSTM for Text Representation**, [[paper]](https://www.aclweb.org/anthology/P18-1030.pdf), [[bibtex]](/Bibtex/Sentence-State%20LSTM%20for%20Text%20Representation.bib), [[poster]](https://www.aclweb.org/anthology/attachments/P18-1030.Poster.pdf), sources: [[leuchine/S-LSTM]](https://github.com/leuchine/S-LSTM), [[bill-kalog/S-LSTM_pytorch]](https://github.com/bill-kalog/S-LSTM_pytorch).
- [2019 EMNLP] **Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks**, [[paper]](https://www.aclweb.org/anthology/D19-1410.pdf), [[bibtex]](https://www.aclweb.org/anthology/D19-1410.bib), sources: [[UKPLab/sentence-transformers]](https://github.com/UKPLab/sentence-transformers).
- [2020 EMNLP] **On the Sentence Embeddings from Pre-trained Language Models**, [[paper]](https://www.aclweb.org/anthology/2020.emnlp-main.733.pdf), [[bibtex]](https://www.aclweb.org/anthology/2020.emnlp-main.733.bib), sources: [[bohanli/BERT-flow]](https://github.com/bohanli/BERT-flow).
- [2021 ArXiv] **SimCSE: Simple Contrastive Learning of Sentence Embeddings**, [[paper]](https://arxiv.org/pdf/2104.08821.pdf), [[bibtex]](/Bibtex/SimCSE%20-%20Simple%20Contrastive%20Learning%20of%20Sentence%20Embeddings.bib), sources: [[princeton-nlp/SimCSE]](https://github.com/princeton-nlp/SimCSE).

## Natural Language Understanding (NLI, Textual Entailment, Sentence Matching)
- [2016 NAACL] **Learning Natural Language Inference with LSTM**, [[paper]](http://www.aclweb.org/anthology/N16-1170), [[bibtex]](/Bibtex/Learning%20Natural%20Language%20Inference%20with%20LSTM.bib), source: [[shuohangwang/SeqMatchSeq]](https://github.com/shuohangwang/SeqMatchSeq).
- [2017 IJCAI] **BiMPM: Bilateral Multi-Perspective Matching for Natural Language Sentences**, [[paper]](https://arxiv.org/pdf/1702.03814.pdf), [[bibtex]](/Bibtex/Bilateral%20Multi-Perspective%20Matching%20for%20Natural%20Language%20Sentences.bib), sources: [[zhiguowang/BiMPM]](https://github.com/zhiguowang/BiMPM).
- [2017 ArXiv] **Distance-based Self-Attention Network for Natural Language Inference**, [[paper]](https://arxiv.org/pdf/1712.02047.pdf), [[bibtex]](/Bibtex/Distance-based%20Self-Attention%20Network%20for%20Natural%20Language%20Inference.bib).
- [2017 ACL] **Enhanced LSTM for Natural Language Inference**, [[paper]](http://aclweb.org/anthology/P17-1152), [[bibtex]](/Bibtex/Enhanced%20LSTM%20for%20Natural%20Language%20Inference.bib), sources: [[lukecq1231/nli]](https://github.com/lukecq1231/nli), [[coetaur0/ESIM]](https://github.com/coetaur0/ESIM), [[HsiaoYetGun/ESIM]](https://github.com/HsiaoYetGun/ESIM), [[sdnr1/EBIM-NLI]](https://github.com/sdnr1/EBIM-NLI), [[JasonForJoy/ESIM-NLI]](https://github.com/JasonForJoy/ESIM-NLI).
- [2018 AAAI] **DiSAN: Directional Self-Attention Network for RNN/CNN-free Language Understanding**, [[paper]](https://arxiv.org/pdf/1709.04696.pdf), [[bibtex]](/Bibtex/DiSAN%20-%20Directional%20Self-Attention%20Network%20for%20RNN%20-%20CNN-free%20Language%20Understanding.bib), sources: [[taoshen58/DiSAN]](https://github.com/taoshen58/DiSAN).
- [2018 IJCAI] **Reinforced Self-Attention Network: a Hybrid of Hard and Soft Attention for Sequence Modeling**, [[paper]](https://www.ijcai.org/proceedings/2018/0604.pdf), [[bibtex]](/Bibtex/Reinforced%20Self-Attention%20Network%20-%20a%20Hybrid%20of%20Hard%20and%20Soft%20Attention%20for%20Sequence%20Modeling.bib).
- [2018 IJCAI] **Hermitian Co-Attention Networks for Text Matching in Asymmetrical Domains**, [[paper]](https://www.ijcai.org/proceedings/2018/0615.pdf), [[bibtex]](/Bibtex/Hermitian%20Co-Attention%20Networks%20for%20Text%20Matching%20in%20Asymmetrical%20Domains.bib).
- [2019 ACL] **Multi-Task Deep Neural Networks for Natural Language Understanding**, [[paper]](https://www.aclweb.org/anthology/P19-1441.pdf), [[bibtex]](/Bibtex/Multi-Task%20Deep%20Neural%20Networks%20for%20Natural%20Language%20Understanding.bib), sources: [[namisan/mt-dnn]](https://github.com/namisan/mt-dnn).
- [2019 AAAI] **Gaussian Transformer: A Lightweight Approach for Natural Language Inference**, [[paper]](https://ojs.aaai.org//index.php/AAAI/article/view/4614), [[bibtex]](/Bibtex/Gaussian%20Transformer%20-%20A%20Lightweight%20Approach%20for%20Natural%20Language%20Inference.bib), sources: [[lzy1732008/GaussionTransformer]](https://github.com/lzy1732008/GaussionTransformer).
- [2020 ACL] **Adversarial NLI: A New Benchmark for Natural Language Understanding**, [[paper]](https://www.aclweb.org/anthology/2020.acl-main.441.pdf), [[bibtex]](https://www.aclweb.org/anthology/2020.acl-main.441.bib), sources: [[facebookresearch/anli]](https://github.com/facebookresearch/anli).
- [2020 ACL] **Mind the Trade-off: Debiasing NLU Models without Degrading the In-distribution Performance**, [[paper]](https://aclanthology.org/2020.acl-main.770.pdf), [[bibtex]](/Bibtex/Mind%20the%20Trade-off%20-%20Debiasing%20NLU%20Models%20without%20Degrading%20the%20In-distribution%20Performance.bib), sources: [[UKPLab/acl2020-confidence-regularization]](https://github.com/UKPLab/acl2020-confidence-regularization).
- [2020 ArXiv] **MultiMix: A Robust Data Augmentation Framework for Cross-Lingual NLP**, [[paper]](https://arxiv.org/pdf/2004.13240.pdf), [[bibtex]](/Bibtex/MultiMix%20-%20A%20Robust%20Data%20Augmentation%20Framework%20for%20Cross-Lingual%20NLP.bib).
- [2020 ICML] **XTREME: A Massively Multilingual Multi-task Benchmark for Evaluating Cross-lingual Generalization**, [[paper]](http://proceedings.mlr.press/v119/hu20b/hu20b.pdf), [[bibtex]](/Bibtex/XTREME%20-%20A%20Massively%20Multilingual%20Multi-task%20Benchmark%20for%20Evaluating%20Cross-lingual%20Generalization.bib), [[supplementary]](http://proceedings.mlr.press/v119/hu20b/hu20b-supp.pdf), [[homepage]](https://sites.research.google/xtreme), sources: [[google-research/xtreme]](https://github.com/google-research/xtreme).
- [2020 ICLR] **Learning the Difference that Makes a Difference with Counterfactually-Augmented Data**, [[paper]](https://openreview.net/pdf?id=Sklgs0NFvr), [[bibtex]](/Bibtex/Learning%20the%20Difference%20that%20Makes%20a%20Difference%20with%20Counterfactually-Augmented%20Data.bib), sources: [[dkaushik96/counterfactually-augmented-data]](https://github.com/dkaushik96/counterfactually-augmented-data).
- [2020 EMNLP] **Zero-Shot Cross-Lingual Transfer with Meta Learning**, [[paper]](https://www.aclweb.org/anthology/2020.emnlp-main.368.pdf), [[bibtex]](https://www.aclweb.org/anthology/2020.emnlp-main.368.bib), sources: [[copenlu/X-MAML]](https://github.com/copenlu/X-MAML).
- [2020 EMNLP] **Towards Debiasing NLU Models from Unknown Biases**, [[paper]](https://aclanthology.org/2020.emnlp-main.613.pdf), [[bibtex]](/Bibtex/Towards%20Debiasing%20NLU%20Models%20from%20Unknown%20Biases.bib), sources: [[UKPLab/emnlp2020-debiasing-unknown]](https://github.com/UKPLab/emnlp2020-debiasing-unknown).
- [2020 EMNLP] **Translation Artifacts in Cross-lingual Transfer Learning**, [[paper]](https://aclanthology.org/2020.emnlp-main.618.pdf), [[bibtex]](/Bibtex/Translation%20Artifacts%20in%20Cross-lingual%20Transfer%20Learning.bib), sources: [[artetxem/esxnli]](https://github.com/artetxem/esxnli).
- [2021 AAAI] **FILTER: An Enhanced Fusion Method for Cross-lingual Language Understanding**, [[paper]](https://arxiv.org/pdf/2009.05166.pdf), [[bibtex]](/Bibtex/FILTER%20-%20An%20Enhanced%20Fusion%20Method%20for%20Cross-lingual%20Language%20Understanding.bib), [[slides]](https://zhegan27.github.io/Papers/filter_slides.pdf), sources: [[yuwfan/FILTER]](https://github.com/yuwfan/FILTER).
- [2021 NAACL] **Towards Interpreting and Mitigating Shortcut Learning Behavior of NLU models**, [[paper]](https://aclanthology.org/2021.naacl-main.71.pdf), [[bibtex]](/Bibtex/Towards%20Interpreting%20and%20Mitigating%20Shortcut%20Learning%20Behavior%20of%20NLU%20models.bib).
- [2021 ACL Findings] **Empowering Language Understanding with Counterfactual Reasoning**, [[paper]](https://aclanthology.org/2021.findings-acl.196.pdf), [[bibtex]](/Bibtex/Empowering%20Language%20Understanding%20with%20Counterfactual%20Reasoning.bib), sources: [[fulifeng/Counterfactual_Reasoning_Model]](https://github.com/fulifeng/Counterfactual_Reasoning_Model).
- [2021 ACL Findings] **DocNLI: A Large-scale Dataset for Document-level Natural Language Inference**, [[paper]](https://aclanthology.org/2021.findings-acl.435.pdf), [[bibtex]](/Bibtex/DocNLI%20-%20A%20Large-scale%20Dataset%20for%20Document-level%20Natural%20Language%20Inference.bib), sources: [[salesforce/DocNLI]](https://github.com/salesforce/DocNLI).
- [2021 ACL] **Syntax-augmented Multilingual BERT for Cross-lingual Transfer**, [[paper]](https://aclanthology.org/2021.acl-long.350.pdf), [[bibtex]](/Bibtex/Syntax-augmented%20Multilingual%20BERT%20for%20Cross-lingual%20Transfer.bib), sources: [[wasiahmad/Syntax-MBERT]](https://github.com/wasiahmad/Syntax-MBERT).
- [2021 ACL] **Consistency Regularization for Cross-Lingual Fine-Tuning**, [[paper]](https://aclanthology.org/2021.acl-long.264.pdf), [[bibtex]](/Bibtex/Consistency%20Regularization%20for%20Cross-Lingual%20Fine-Tuning.bib), sources: [[bozheng-hit/xTune]](https://github.com/bozheng-hit/xTune).

## Sentence Representation Evaluation
- [2018 EMNLP] **GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding**, [[paper]](http://aclweb.org/anthology/W18-5446), [[bibtex]](/Bibtex/GLUE%20-%02A%20Multi-Task%20Benchmark%20and%20Analysis%20Platform%20for%20Natural%20Language%20Understanding.bib), [[homepage]](https://gluebenchmark.com), sources: [[nyu-mll/GLUE-baselines]](https://github.com/nyu-mll/GLUE-baselines).
- [2019 ICLR] **GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding**, [[paper]](https://openreview.net/pdf?id=rJ4km2R5t7), [[bibtex]](/Bibtex/GLUE%20-%02A%20Multi-Task%20Benchmark%20and%20Analysis%20Platform%20for%20Natural%20Language%20Understanding.bib), [[homepage]](https://gluebenchmark.com), sources: [[nyu-mll/GLUE-baselines]](https://github.com/nyu-mll/GLUE-baselines).
