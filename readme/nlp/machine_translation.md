# Machine Translation

- **A Convolutional Encoder Model for Neural Machine Translation**, [[paper]](https://arxiv.org/abs/1611.02344), sources: [[facebookresearch/fairseq]](https://github.com/facebookresearch/fairseq).
- **Neural Machine Translation by Jointly Learning to Align and Translate**, [[paper]](https://arxiv.org/abs/1409.0473), sources: [[lisa-groundhog/GroundHog]](https://github.com/lisa-groundhog/GroundHog/tree/master/experiments/nmt), [[tensorflow/nmt]](https://github.com/tensorflow/nmt).
- **On the properties of neural machine Translation Encoder-Decoder Approaches**, [[paper]](https://arxiv.org/abs/1409.1259).
- **Context Models for OOV Word Translation in Low-Resource Language**, [[paper]](https://arxiv.org/abs/1801.08660).
- **Effective Approaches to Attention-based Neural Machine Translation**, [[paper]](http://aclweb.org/anthology/D15-1166), [[HarvardNLP homepage]](http://nlp.seas.harvard.edu/code/), sources: [[dillonalaird/Attention]](https://github.com/dillonalaird/Attention), [[tensorflow/nmt]](https://github.com/tensorflow/nmt).
- **Attention is All You Need**, [[paper]](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf), sources: [[Kyubyong/transformer]](https://github.com/Kyubyong/transformer), [[jadore801120/attention-is-all-you-need-pytorch]](https://github.com/jadore801120/attention-is-all-you-need-pytorch), [[DongjunLee/transformer-tensorflow]](https://github.com/DongjunLee/transformer-tensorflow).