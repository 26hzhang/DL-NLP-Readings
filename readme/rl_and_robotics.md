## Reinforencement Learning and Robotics

## Reinforencement Learning
- [Key Papers in Deep RL](https://spinningup.openai.com/en/latest/spinningup/keypapers.html).
- [2013 NIPS] **Playing Atari with Deep Reinforcement Learning**, [[paper]](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf), [[bibtex]](/Bibtex/Playing%20Atari%20with%20Deep%20Reinforcement%20Learning.bib), [[blog]](https://keon.io/deep-q-learning/), sources: [[kuz/DeepMind-Atari-Deep-Q-Learner]](https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner), [[ethanscho/dqn-atari-tensorflow]](https://github.com/ethanscho/dqn-atari-tensorflow), [[carpedm20/deep-rl-tensorflow]](https://github.com/carpedm20/deep-rl-tensorflow).
- [2014 ICML] **Deterministic Policy Gradient Algorithms**, [[paper]](http://proceedings.mlr.press/v32/silver14.pdf), [[supplementary]](http://proceedings.mlr.press/v32/silver14-supp.pdf), [[bibtex]](/Bibtex/Deterministic%20Policy%20Gradient%20Algorithms.bib), [[blog]](https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html), sources: [[cookbenjamin/DDPG]](https://github.com/cookbenjamin/DDPG).
- [2015 Nature] **DQN: Human-level control through deep reinforcement learning**, [[paper]](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf), [[bibtex]](/Bibtex/DQN.bib), [[blog]](https://deepmind.com/research/publications/human-level-control-through-deep-reinforcement-learning/), [[code-page]](https://stable-baselines.readthedocs.io/en/master/), sources: [[openai/baselines]](https://github.com/openai/baselines), [[hill-a/stable-baselines]](https://github.com/hill-a/stable-baselines).
- [2016 ICML] **Asynchronous Methods for Deep Reinforcement Learning**, [[paper]](http://proceedings.mlr.press/v48/mniha16.pdf), [[bibtex]](/Bibtex/Asynchronous%20Methods%20for%20Deep%20Reinforcement%20Learning.bib), [[supplementary]](http://proceedings.mlr.press/v48/mniha16-supp.pdf), sources: [[miyosuda/async_deep_reinforce]](https://github.com/miyosuda/async_deep_reinforce).
- [2016 ICML] **Dueling DQN: Dueling Network Architectures for Deep Reinforcement Learning**, [[paper]](http://proceedings.mlr.press/v48/wangf16.pdf), [[bibtex]](/Bibtex/Dueling%20Network%20Architectures%20for%20Deep%20Reinforcement%20Learning.bib).
- [2016 ICLR] **Prioritized DQN: Prioritized Experience Replay**, [[paper]](https://arxiv.org/pdf/1511.05952.pdf), [[bibtex]](/Bibtex/Prioritized%20Experience%20Replay.bib), [[blog]](https://danieltakeshi.github.io/2019/07/14/per/), sources: [[Damcy/prioritized-experience-replay]](https://github.com/Damcy/prioritized-experience-replay).
- [2017 ICLR] **An Actor Critic Algorithm for Structured Prediction**, [[paper]](https://openreview.net/pdf?id=SJDaqqveg), [[bibtex]](/Bibtex/An%20Actor%20Critic%20Algorithm%20for%20Structured%20Prediction.bib), sources: [[rizar/actor-critic-public]](https://github.com/rizar/actor-critic-public).
- [2017 ICML] **Categorical DQN: A Distributional Perspective on Reinforcement Learning**, [[paper]](http://proceedings.mlr.press/v70/bellemare17a/bellemare17a.pdf), [[bibtex]](/Bibtex/A%20Distributional%20Perspective%20on%20Reinforcement%20Learning.bib), sources: [[Silvicek/distributional-dqn]](https://github.com/Silvicek/distributional-dqn).
- [2017 ICML] **Curiosity-driven Exploration by Self-supervised Prediction**, [[paper]](https://pathak22.github.io/noreward-rl/resources/icml17.pdf), [[bibtex]](/Bibtex/Curiosity-driven%20Exploration%20by%20Self-supervised%20Prediction.bib), sources: [[pathak22/noreward-rl]](https://github.com/pathak22/noreward-rl).
- [2018 ICLR] **NoisyNet DQN: Noisy Networks for Exploration**, [[paper]](https://openreview.net/pdf?id=rywHCPkAW), [[bibtex]](/Bibtex/Noisy%20Networks%20for%20Exploration.bib), sources: [[Kaixhin/NoisyNet-A3C]](https://github.com/Kaixhin/NoisyNet-A3C).
- [2018 AAAI] **Rainbow: Combining Improvements in Deep Reinforcement Learning**, [[paper]](https://pdfs.semanticscholar.org/75e5/b72cf0eb3c1531ec241e6ca8a4308a70f147.pdf), [[bibtex]](/Bibtex/Rainbow%20-%20Combining%20Improvements%20in%20Deep%20Reinforcement%20Learning.bib), sources: [[Kaixhin/Rainbow]](https://github.com/Kaixhin/Rainbow).
- [2018 AAAI] **Deep Reinforcement Learning that Matters**, [[paper]](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16669/16677), [[bibtex]](/Bibtex/Deep%20Reinforcement%20Learning%20that%20Matters.bib), sources: [[Breakend/DeepReinforcementLearningThatMatters]](https://github.com/Breakend/DeepReinforcementLearningThatMatters).
- [2019 TICS] **Reinforcement Learning, Fast and Slow**, [[paper]](https://www.cell.com/action/showPdf?pii=S1364-6613%2819%2930061-0), [[bibtex]](/Bibtex/Reinforcement%20Learning%20Fast%20and%20Slow.bib).
- [2020 ICML] **Intrinsic Reward Driven Imitation Learning via Generative Model**, [[paper]](https://proceedings.icml.cc/static/paper_files/icml/2020/3696-Paper.pdf), [[bibtex]](/Bibtex/Intrinsic%20Reward%20Driven%20Imitation%20Learning%20via%20Generative%20Model.bib).

# Robotics and RL Applications
- [2014 ACL] **Learning Spatial Knowledge for Text to 3D Scene Generation**, [[paper]](https://www.aclweb.org/anthology/D14-1217), [[bibtex]](/Bibtex/Learning%20Spatial%20Knowledge%20for%20Text%20to%203D%20Scene%20Generation.bib).
- [2015 IROS] **Neural Network based Model for Visual-motor Integration Learning of Robotâ€™s Drawing Behavior: Association of a Drawing Motion from a Drawn Image**, [[paper]](/Documents/Papers/Neural%20Network%20based%20Model%20for%20Visual-motor%20Integration%20Learning%20of%20Robots%20Drawing%20Behavior%20-%20Association%20of%20a%20Drawing%20Motion%20from%20a%20Drawn%20Image.pdf), [[bibtex]](/Bibtex/Neural%20Network%20based%20Model%20for%20Visual-motor%20Integration%20Learning%20of%20Robots%20Drawing%20Behavior%20-%20Association%20of%20a%20Drawing%20Motion%20from%20a%20Drawn%20Image.bib).
- [2016 ICRA] **Learning to Generalize 3D Spatial Relationships**, [[paper]](/Documents/Papers/Learning%20to%20Generalize%203D%20Spatial%20Relationships.pdf), [[bibtex]](/Bibtex/Learning%20to%20Generalize%203D%20Spatial%20Relationships.bib).
- [2016 TCDS] **Spatial Concept Acquisition for a Mobile Robot That Integrates Self-Localization and Unsupervised Word Discovery From Spoken Sentences**, [[paper]](https://arxiv.org/pdf/1602.01208.pdf), [[bibtex]](/Bibtex/Spatial%20Concept%20Acquisition.bib).
- [2017 AAAI] **Natural Language Acquisition and Grounding for Embodied Robotic Systems**, [[paper]](https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14913/14038), [[bibtex]](/Bibtex/Natural%20Language%20Acquisition%20and%20Grounding%20for%20Embodied%20Robotic%20Systems.bib).
- [2017 PMLR] **Opportunistic Active Learning for Grounding Natural Language Descriptions**, [[paper]](http://proceedings.mlr.press/v78/thomason17a/thomason17a.pdf), [[bibtex]](/Bibtex/Opportunistic%20Active%20Learning%20for%20Grounding%20Natural%20Language%20Descriptions.bib), sources: [[thomason-jesse/perception_classifiers]](https://github.com/thomason-jesse/perception_classifiers/tree/active_learning).
- [2018 ArXiv] **A Learning Framework for High Precision Industrial Assembly**, [[paper]](https://arxiv.org/pdf/1809.08548.pdf), [[bibtex]](/Bibtex/A%20Learning%20Framework%20for%20High%20Precision%20Industrial%20Assembly.bib).
- [2018 AAAI] **Guiding Exploratory Behaviors for Multi-Modal Grounding of Linguistic Descriptions**, [[paper]](https://www.eecs.tufts.edu/~jsinapov/papers/Thomason_AAAI_2018.pdf), [[bibtex]](/Bibtex/Guiding%20Exploratory%20Behaviors%20for%20Multi-Modal%20Grounding%20of%20Linguistic%20Descriptions.bib), sources: [[thomason-jesse/object_exploration]](https://github.com/thomason-jesse/object_exploration).
- [2018 Robotics] **Learning Task-Oriented Grasping for Tool Manipulation from Simulated Self-Supervision**, [[paper]](http://www.roboticsproceedings.org/rss14/p12.pdf), [[bibtex]](/Bibtex/Learning%20Task-Oriented%20Grasping%20for%20Tool%20Manipulation%20from%20Simulated%20Self-Supervision.bib).
- [2018 ICRA] **Text2Action: Generative Adversarial Synthesis from Language to Action**, [[paper]](https://arxiv.org/pdf/1710.05298.pdf), [[bibtex]](/Bibtex/Text2Action.bib).
- [2018 CoRL] **QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation**, [[paper]](https://arxiv.org/pdf/1806.10293.pdf), [[bibtex]](/Bibtex/QT-Opt.bib), [[homepage]](https://sites.google.com/view/qtopt), sources: [[DeepX-inc/machina]](https://github.com/DeepX-inc/machina).
- [2018 CoRL] **Sim-to-Real Transfer with Neural-Augmented Robot Simulation**, [[paper]](http://proceedings.mlr.press/v87/golemo18a/golemo18a.pdf), [[bibtex]](/Bibtex/Sim-to-Real%20Transfer%20with%20Neural-Augmented%20Robot%20Simulation.bib), sources: [[aalitaiga/sim-to-real]](https://github.com/aalitaiga/sim-to-real/).
- [2018 CoRL] **Task-Embedded Control Networks for Few-Shot Imitation Learning**, [[paper]](http://proceedings.mlr.press/v87/james18a/james18a.pdf), [[bibtex]](/Bibtex/Task-Embedded%20Control%20Networks%20for%20Few-Shot%20Imitation%20Learning.bib), sources: [[stepjam/TecNets]](https://github.com/stepjam/TecNets).
- [2018 ICML] **QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning**, [[paper]](http://proceedings.mlr.press/v80/rashid18a/rashid18a.pdf), [[bibtex]](/Bibtex/QMIX.bib), [[supplementary]](http://proceedings.mlr.press/v80/rashid18a/rashid18a-supp.pdf).
- [2018 ICRA] **Vision-Based Multi-Task Manipulation for Inexpensive Robots Using End-To-End Learning from Demonstration**, [[paper]](https://arxiv.org/pdf/1707.02920.pdf), [[bibtex]](/Bibtex/Vision-Based%20Multi-Task%20Manipulation%20for%20Inexpensive%20Robots%20Using%20End-To-End%20Learning%20from%20Demonstration.bib).
- [2018 AAAI] **Learning Interpretable Spatial Operations in a Rich 3D Blocks World**, [[paper]](https://arxiv.org/pdf/1712.03463.pdf), [[bibtex]](/Bibtex/Learning%20Interpretable%20Spatial%20Operations%20in%20a%20Rich%203D%20Blocks%20World.bib), [[dataset]](https://groundedlanguage.github.io), sources: [[ybisk/GroundedLanguage]](https://github.com/ybisk/GroundedLanguage).
- [2018 NeurIPS] **Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding**, [[paper]](https://papers.nips.cc/paper/7381-neural-symbolic-vqa-disentangling-reasoning-from-vision-and-language-understanding.pdf), [[bibtex]](/Bibtex/Neural-Symbolic%20VQA%20-%20Disentangling%20Reasoning%20from%20Vision%20and%20Language%20Understanding.bib), sources: [[kexinyi/ns-vqa]](https://github.com/kexinyi/ns-vqa).
- [2018 RSS] **Push-Net: Deep Planar Pushing for Objects with Unknown Physical Properties**, [[paper]](http://www.roboticsproceedings.org/rss14/p24.pdf), [[bibtex]](/Bibtex/Push-Net%20-%20Deep%20Planar%20Pushing%20for%20Objects%20with%20Unknown%20Physical%20Properties.bib), sources: [[ljklonepiece/PushNet]](https://github.com/ljklonepiece/PushNet).
- [2019 IROS] **Robot Artist Performs Cartoon Style Facial Portrait Painting**, [[paper]](/Documents/Papers/Robot%20Artist%20Performs%20Cartoon%20Style%20Facial%20Portrait%20Painting.pdf), [[bibtex]](/Bibtex/Robot%20Artist%20Performs%20Cartoon%20Style%20Facial%20Portrait%20Painting.bib).
- [2019 CVPR] **Sim-to-Real via Sim-to-Sim: Data-efficient Robotic Grasping via Randomized-to-Canonical Adaptation Networks**, [[paper]](https://arxiv.org/pdf/1812.07252.pdf), [[bibtex]](/Bibtex/Sim-to-Real%20via%20Sim-to-Sim.bib), [[homepage]](https://sites.google.com/view/rcan/).
- [2019 TII] **Feedback Deep Deterministic Policy Gradient With Fuzzy Reward for Robotic Multiple Peg-in-Hole Assembly Tasks**, [[paper]](/Documents/Papers/Feedback%20Deep%20Deterministic%20Policy%20Gradient%20With%20Fuzzy%20Reward%20for%20Robotic%20Multiple%20Peg-in-Hole%20Assembly%20Tasks.pdf), [[bibtex]](/Bibtex/Feedback%20Deep%20Deterministic%20Policy%20Gradient%20With%20Fuzzy%20Reward%20for%20Robotic%20Multiple%20Peg-in-Hole%20Assembly%20Tasks.bib), sources: [[hzm2016/Peg_in_hole_assembly]](https://github.com/hzm2016/Peg_in_hole_assembly).
- [2019 ICRA] **Sim-to-Real Transfer Learning using Robustified Controllers in Robotic Tasks involving Complex Dynamics**, [[paper]](http://www.merl.com/publications/docs/TR2018-202.pdf), [[bibtex]](/Bibtex/Sim-to-Real%20Transfer%20Learning%20using%20Robustified%20Controllers%20in%20Robotic%20Tasks%20involving%20Complex%20Dynamics.bib).
- [2019 ICLR] **The Neuro-Symbolic Concept Learner: Interpreting Scenes Words and Sentences from Natural Supervision**, [[paper]](https://openreview.net/pdf?id=rJgMlhRctm), [[bibtex]](/Bibtex/Neuro-Symbolic%20Concept%20Learner%20-%20Interpreting%20Scenes%20Words%20and%20Sentences%20from%20Natural%20Supervision.bib), [[homepage]](http://nscl.csail.mit.edu), sources: [[vacancy/NSCL-PyTorch-Release]](https://github.com/vacancy/NSCL-PyTorch-Release).
