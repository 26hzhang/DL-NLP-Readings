# Other Research Works

- Self-supervised Learning resources: [[jason718/awesome-self-supervised-learning]](https://github.com/jason718/awesome-self-supervised-learning).

## Neural Tuning Machine
- [2014 ArXiv] **Neural Turing Machines**, [[paper]](https://arxiv.org/abs/1410.5401.pdf), [[bibtex]](/Bibtex/ntm.bib) sources: [[carpedm20/NTM-tensorflow]](https://github.com/carpedm20/NTM-tensorflow).
- [2016 Nature] **Hybrid Computing Using a Neural Network with Dynamic External Memory**, [[paper]](https://pdfs.semanticscholar.org/7635/78fa9003f6c0f735bc3250fc2116f6100463.pdf), [[bibtex]](/Bibtex/Hybrid%20Computing%20Using%20a%20Neural%20Network%20with%20Dynamic%20External%20Memory.bib) sources: [[deepmind/dnc]](https://github.com/deepmind/dnc), [[claymcleod/tf-differentiable-neural-computer]](https://github.com/claymcleod/tf-differentiable-neural-computer).

## Memory Network
- [2015 ICLR] **Memory Networks**, [[paper]](https://arxiv.org/pdf/1410.3916.pdf), [[bibtex]](/Bibtex/Memory%20networks.bib) sources: [[facebook/MemNN]](https://github.com/facebook/MemNN).
- [2015 NIPS] **End-To-End Memory Networks**, [[paper]](https://arxiv.org/pdf/1503.08895.pdf), [[bibtex]](/Bibtex/End-To-End%20Memory%20Networks.bib), sources: [[facebook/MemNN]](https://github.com/facebook/MemNN), [[seominjoon/memnn-tensorflow]](https://github.com/seominjoon/memnn-tensorflow), [[domluna/memn2n]](https://github.com/domluna/memn2n), [[carpedm20/MemN2N-tensorflow]](https://github.com/carpedm20/MemN2N-tensorflow).

## Highway Network
- [2015 ICMLW] **Highway Networks**, [[paper]](https://arxiv.org/abs/1505.00387), [[bibtex]](/Bibtex/Highway%20Networks.bib), [[homepage]](http://people.idsia.ch/~rupesh/very_deep_learning/), sources: [[IsaacChanghau/AmusingPythonCodes/highway_networks]](https://github.com/IsaacChanghau/AmusingPythonCodes/tree/master/highway_networks), [[lucko515/fully-connected-highway-network]](https://github.com/lucko515/fully-connected-highway-network), [[fomorians/highway-cnn]](https://github.com/fomorians/highway-cnn).
- [2015 NIPS] **Training Very Deep Networks**, [[paper]](https://arxiv.org/abs/1507.06228), [[bibtex]](/Bibtex/Training%20Very%20Deep%20Networks.bib), sources: [[trangptm/HighwayNetwork]](https://github.com/trangptm/HighwayNetwork).
- [2017 ICML] **Recurrent Highway Networks**, [[paper]](https://arxiv.org/abs/1607.03474), [[bibtex]](/Bibtex/Recurrent%20Highway%20Networks.bib), sources: [[julian121266/RecurrentHighwayNetworks]](https://github.com/julian121266/RecurrentHighwayNetworks).

## Error Correcting Output Code (ECOC)
- [2016 ArXiv] **N-ary Error Correcting Coding Scheme**, [[paper]](https://arxiv.org/pdf/1603.05850.pdf), [[bibtex]](/Bibtex/N-ary%20Error%20Correcting%20Coding%20Scheme.bib).
- [2018 JIIS] **Experimental Validation for N-ary Error Correcting Output Codes for Ensemble Learning of Deep Neural Networks**, [[paper]](/Documents/Papers/Experimental%20Validation%20for%20N-ary%20Error%20Correcting%20Output%20Codes%20for%20Ensemble%20Learning%20of%20Deep%20Neural%20Networks.pdf), [[bibtex]](/Bibtex/Experimental%20Validation%20for%20N-ary%20Error%20Correcting%20Output%20Codes%20for%20Ensemble%20Learning%20of%20Deep%20Neural%20Networks.bib).
- [2020 MobiMedia], **Deep N-ary Error Correcting Output Codes**, [[paper]](https://arxiv.org/pdf/2009.10465.pdf), [[bibtex]](/Bibtex/Deep%20N-ary%20Error%20Correcting%20Output%20Codes.bib), sources: [[IsaacChanghau/DeepNaryECOC]](https://github.com/IsaacChanghau/DeepNaryECOC).

## Label Embeddings
- [2018 ACL] **Multi-Task Label Embedding for Text Classification**, [[paper]](https://www.aclweb.org/anthology/D18-1484), [[bibtex]](/Bibtex/Multi-Task%20Label%20Embedding%20for%20Text%20Classification.bib), [[blog]](https://www.jianshu.com/p/4bbe061f0acd).
- [2018 ACL] **Joint Embedding of Words and Labels for Text Classification**, [[paper]](https://www.aclweb.org/anthology/P18-1216), [[bibtex]](/Bibtex/Joint%20Embedding%20of%20Words%20and%20Labels%20for%20Text%20Classification.bib), [[poster]](https://www.aclweb.org/anthology/attachments/P18-1216.Poster.pdf), sources: [[guoyinwang/LEAM]](https://github.com/guoyinwang/LEAM).
- [2018 TACL] **GILE: A Generalized Input-Label Embedding for Text Classification**, [[paper]](https://www.aclweb.org/anthology/Q19-1009), [[bibtex]](/Bibtex/GILE%20-%20A%20Generalized%20Input-Label%20Embedding%20for%20Text%20Classification.bib), sources: [[idiap/gile]](https://github.com/idiap/gile).

## Recommendation System
- [2017 IJCAI] **DeepFM - A Factorization-Machine based Neural Network for CTR Prediction**, [[paper]](https://www.ijcai.org/proceedings/2017/0239.pdf), [[bibtex]](/Bibtex/DeepFM%20-%20A%20Factorization-Machine%20based%20Neural%20Network%20for%20CTR%20Prediction.bib), sources: [[shenweichen/DeepCTR]](https://github.com/shenweichen/DeepCTR).
- [2018 ArXiv] **Next Item Recommendation with Self-Attention**, [[paper]](https://arxiv.org/pdf/1808.06414.pdf), [[bibtex]](/Bibtex/Next%20Item%20Recommendation%20with%20Self-Attention.bib).
- [2018 ICDM] **Self-Attentive Sequential Recommendation**, [[paper]](https://arxiv.org/pdf/1808.09781.pdf), [[bibtex]](/Bibtex/Self-Attentive%20Sequential%20Recommendation.bib), sources: [[kang205/SASRec]](https://github.com/kang205/SASRec).
- [2018 KDD] **Multi-Pointer Co-Attention Networks for Recommendation**, [[paper]](https://arxiv.org/pdf/1801.09251.pdf), [[bibtex]](/Bibtex/Multi-Pointer%20Co-Attention%20Networks%20for%20Recommendation.bib), sources: [[vanzytay/KDD2018_MPCN]](https://github.com/vanzytay/KDD2018_MPCN).
- [2019 RecSys] **Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches**, [[paper]](https://arxiv.org/pdf/1907.06902.pdf), [[bibtex]](/Bibtex/Are%20We%20Really%20Making%20Much%20Progress%20A%20Worrying%20Analysis%20of%20Recent%20Neural%20Recommendation%20Approaches.bib), sources: [[MaurizioFD/RecSys2019_DeepLearning_Evaluation]](https://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation).
- [2020 ArXiv] **A Critical Study on Data Leakage in Recommender System Offline Evaluation**, [[paper]](https://arxiv.org/pdf/2010.11060.pdf), [[bibtex]](/Bibtex/A%20Critical%20Study%20on%20Data%20Leakage%20in%20Recommender%20System%20Offline%20Evaluation.bib).
- [2020 SIGIR] **A Re-visit of the Popularity Baseline in Recommender Systems**, [[paper]](https://arxiv.org/pdf/2005.13829.pdf), [[bibtex]](/Bibtex/A%20Re-visit%20of%20the%20Popularity%20Baseline%20in%20Recommender%20Systems.bib).
- [2021 SIGIR] **Causal Intervention for Leveraging Popularity Bias in Recommendation**, [[paper]](https://dl.acm.org/doi/pdf/10.1145/3404835.3462875), [[bibtex]](/Bibtex/Causal%20Intervention%20for%20Leveraging%20Popularity%20Bias%20in%20Recommendation.bib), sources: [[zyang1580/PDA]](https://github.com/zyang1580/PDA).
- [2021 ArXiv] **SELFCF: A Simple Framework for Self-supervised Collaborative Filtering**, [[paper]](https://arxiv.org/pdf/2107.03019.pdf), [[bibtex]](/Bibtex/SELFCF%20-%20A%20Simple%20Framework%20for%20Self-supervised%20Collaborative%20Filtering.bib), sources: [[enoche/SelfCF]](https://github.com/enoche/SelfCF).

## Network Architecture Search
- [2019 ICLR] **DARTS: Differentiable Architecture Search**, [[paper]](https://openreview.net/pdf?id=S1eYHoC5FX), [[bibtex]](/Bibtex/DARTS%20-%20Differentiable%20Architecture%20Search.bib), [[homepage]](https://ai.google/research/pubs/pub47800/), sources: [[quark0/darts]](https://github.com/quark0/darts).
- [2019 CVPR] **Searching for A Robust Neural Architecture in Four GPU Hours**, [[paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Dong_Searching_for_a_Robust_Neural_Architecture_in_Four_GPU_Hours_CVPR_2019_paper.pdf), [[bibtex]](/Bibtex/Searching%20for%20A%20Robust%20Neural%20Architecture%20in%20Four%20GPU%20Hours.bib), sources: [[D-X-Y/GDAS]](https://github.com/D-X-Y/GDAS).

## Network Structure Pruning
- [2019 ICML] **EigenDamage: Structured Pruning in the Kronecker-Factored Eigenbasis**, [[paper]](http://proceedings.mlr.press/v97/wang19g/wang19g.pdf), [[bibtex]](/Bibtex/EigenDamage%20-%20Structured%20Pruning%20in%20the%20Kronecker-Factored%20Eigenbasis.bib), [[supplementary]](http://proceedings.mlr.press/v97/wang19g/wang19g-supp.pdf), sources: [[alecwangcq/EigenDamage-Pytorch]](https://github.com/alecwangcq/EigenDamage-Pytorch).
- [2019 CVPR] **Filter Pruning via Geometric Median for Deep Convolutional Neural Networks Acceleration**, [[paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Filter_Pruning_via_Geometric_Median_for_Deep_Convolutional_Neural_Networks_CVPR_2019_paper.pdf), [[bibtex]](/Bibtex/Filter%20Pruning%20via%20Geometric%20Median%20for%20Deep%20Convolutional%20Neural%20Networks%20Acceleration.bib), sources: [[he-y/filter-pruning-geometric-median]](https://github.com/he-y/filter-pruning-geometric-median).

## Neural Network Optimization
- [2009 ICML] **Curriculum Learning**, [[paper]](https://ronan.collobert.com/pub/matos/2009_curriculum_icml.pdf), [[bibtex]](/Bibtex/Curriculum%20Learning.bib).
- [2010 AISTATS] **Understanding the difficulty of training deep feedforward neural networks**, [[paper]](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf), [[bibtex]](/Bibtex/Understanding%20the%20difficulty%20of%20training%20deep%20feedforward%20neural%20networks.bib).
- [2011 ICML] **On Optimization Methods for Deep Learning**, [[paper]](http://ai.stanford.edu/~quocle/LeNgiCoaLahProNg11.pdf), [[bibtex]](/Bibtex/On%20Optimization%20Methods%20for%20Deep%20Learning.bib), [[homepage]](http://www.andrewng.org/portfolio/on-optimization-methods-for-deep-learning/).
- [2013 ICML] **Maxout Networks**, [[paper]](https://arxiv.org/pdf/1302.4389.pdf), [[bibtex]](/Bibtex/Maxout%20Networks.bib), sources: [[philipperemy/tensorflow-maxout]](https://github.com/philipperemy/tensorflow-maxout).
- [2014 JMLR] **Dropout: A Simple Way to Prevent Neural Networks from Overfitting**, [[paper]](http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf), [[bibtex]](/Bibtex/Dropout.bib).
- [2015 ICCV] **Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification**, [[paper]](https://arxiv.org/abs/1502.01852), [[bibtex]](/Bibtex/Delving%20Deep%20into%20Rectifiers.bib), [[Kaiming He's homepage]](http://kaiminghe.com), sources: [[nutszebra/prelu_net]](https://github.com/nutszebra/prelu_net).
- [2015 ICML] **Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift**, [[paper]](https://arxiv.org/abs/1502.03167), [[bibtex]](/Bibtex/Batch%20Normalization.bib), sources: [[tomokishii/mnist_cnn_bn.py]](https://gist.github.com/tomokishii/0ce3bdac1588b5cca9fa5fbdf6e1c412).
- [2016 ICLR] **Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)**, [[paper]](https://arxiv.org/abs/1511.07289), [[bibtex]](/Bibtex/ELUs.bib).
- [2016 ArXiv] **An overview of gradient descent optimization algorithms**, [[paper]](https://arxiv.org/abs/1609.04747), [[bibtex]](/Bibtex/An%20overview%20of%20gradient%20descent%20optimization%20algorithms.bib), [[slides]](https://qdata.github.io/deep2Read//talks/20171031-Ceyer.pdf).
- [2016 ArXiv] **Layer Normalization**, [[paper]](https://arxiv.org/abs/1607.06450), [[bibtex]](/Bibtex/Layer%20Normalization.bib), sources: [[ryankiros/layer-norm]](https://github.com/ryankiros/layer-norm), [[pbhatia243/tf-layer-norm]](https://github.com/pbhatia243/tf-layer-norm), [[NickShahML/tensorflow_with_latest_papers]](https://github.com/NickShahML/tensorflow_with_latest_papers).
- [2016 ICLR] **Incorporating Nesterov Momentum into Adam**, [[paper]](https://openreview.net/pdf?id=OM0jvwB8jIp57ZJjtNEZ), [[bibtex]](/Bibtex/Incorporating%20Nesterov%20Momentum%20into%20Adam.bib).
- [2016 ECCV] **Layer Dropout: Deep Networks with Stochastic Depth**, [[paper]](https://arxiv.org/pdf/1603.09382.pdf), [[bibtex]](/Bibtex/Layer%20Dropout.bib), [[poster]](http://www.eccv2016.org/files/posters/S-3A-08.pdf), sources: [[yueatsprograms/Stochastic_Depth]](https://github.com/yueatsprograms/Stochastic_Depth), [[samjabrahams/stochastic-depth-tensorflow]](https://github.com/samjabrahams/stochastic-depth-tensorflow).
- [2017 NIPS] **Self-Normalizing Neural Networks**, [[paper]](https://arxiv.org/abs/1706.02515), [[bibtex]](/Bibtex/Self-Normalizing%20Neural%20Networks.bib), sources: [[shaohua0116/Activation-Visualization-Histogram]](https://github.com/shaohua0116/Activation-Visualization-Histogram), [[bioinf-jku/SNNs]](https://github.com/bioinf-jku/SNNs).
- [2017 ICLR] **Recurrent Batch Normalization**, [[paper]](https://arxiv.org/abs/1603.09025), [[bibtex]](/Bibtex/Recurrent%20Batch%20Normalization.bib), sources: [[cooijmanstim/recurrent-batch-normalization]](https://github.com/cooijmanstim/recurrent-batch-normalization), [[jihunchoi/recurrent-batch-normalization-pytorch]](https://github.com/jihunchoi/recurrent-batch-normalization-pytorch).
- [2018 AAAI] **Adversarial Dropout for Supervised and Semi-Supervised Learning**, [[paper]](https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16322/16639), [[bibtex]](/Bibtex/Adversarial%20Dropout%20for%20Supervised%20and%20Semi-Supervised%20Learning.bib), sources: [[sungraepark/Adversarial-Dropout]](https://github.com/sungraepark/Adversarial-Dropout).
- [2019 NeurIPS] **Understanding and Improving Layer Normalization**, [[paper]](https://papers.nips.cc/paper/2019/file/2f4fe03d77724a7217006e5d16728874-Paper.pdf), [[bibtex]](/Bibtex/Understanding%20and%20Improving%20Layer%20Normalization.bib), sources: [[lancopku/AdaNorm]](https://github.com/lancopku/AdaNorm).
- [2019 NeurIPS] **Positional Normalization**, [[paper]](https://papers.nips.cc/paper/2019/file/6d0f846348a856321729a2f36734d1a7-Paper.pdf), [[bibtex]](/Bibtex/Positional%20Normalization.bib), sources: [[Boyiliee/PONO]](https://github.com/Boyiliee/PONO).
- [2020 ArXiv] **On Layer Normalization in the Transformer Architecture**, [[paper]](https://arxiv.org/pdf/2002.04745.pdf), [[bibtex]](/Bibtex/On%20Layer%20Normalization%20in%20the%20Transformer%20Architecture.bib).

## Categorical Reparameterization and Its Applications
- [2017 ICLR] **Categorical Reparameterization with Gumbel-SoftMax**, [[paper]](https://openreview.net/pdf?id=rkE3y85ee), [[bibtex]](/Bibtex/Categorical%20Reparameterization%20with%20Gumbel-SoftMax.bib), sources: [[ericjang/gumbel-softmax]](https://github.com/ericjang/gumbel-softmax).
- [2017 ICLR] **The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables**, [[paper]](http://www.stats.ox.ac.uk/~cmaddis/pubs/concrete.pdf), [[bibtex]](/Bibtex/The%20Concrete%20Distribution%20-%20A%20Continuous%20Relaxation%20of%20Discrete%20Random%20Variables.bib), sources: [[pytorch/relaxed_categorical]](https://github.com/pytorch/pytorch/blob/master/torch/distributions/relaxed_categorical.py).
- [2018 ICLR] **Learning Latent Permutations with Gumbel-Sinkhorn Networks**, [[paper]](https://openreview.net/pdf?id=Byt3oJ-0W), [[bibtex]](/Bibtex/Learning%20Latent%20Permutations%20with%20Gumbel-Sinkhorn%20Networks.bib), sources: [[google/gumbel_sinkhorn]](https://github.com/google/gumbel_sinkhorn), [[HeddaCohenIndelman/Learning-Gumbel-Sinkhorn-Permutations-w-Pytorch]](https://github.com/HeddaCohenIndelman/Learning-Gumbel-Sinkhorn-Permutations-w-Pytorch).
- [2018 TCSVT] **Sharp Attention Network via Adaptive Sampling for Person Re-identification**, [[paper]](https://arxiv.org/pdf/1805.02336.pdf), [[bibtex]](/Bibtex/Sharp%20Attention%20Network%20via%20Adaptive%20Sampling%20for%20Person%20Re-identification.bib).
- [2019 CVPR] **Modeling Point Clouds with Self-Attention and Gumbel Subset Sampling**, [[paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Yang_Modeling_Point_Clouds_With_Self-Attention_and_Gumbel_Subset_Sampling_CVPR_2019_paper.pdf), [[bibtex]](/Bibtex/Modeling%20Point%20Clouds%20with%20Self-Attention%20and%20Gumbel%20Subset%20Sampling.bib).
- [2019 CVPR] **Searching for A Robust Neural Architecture in Four GPU Hours**, [[paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Dong_Searching_for_a_Robust_Neural_Architecture_in_Four_GPU_Hours_CVPR_2019_paper.pdf), [[bibtex]](/Bibtex/Searching%20for%20A%20Robust%20Neural%20Architecture%20in%20Four%20GPU%20Hours.bib), sources: [[D-X-Y/GDAS]](https://github.com/D-X-Y/GDAS).
- [2020 ACL] **How Does Selective Mechanism Improve Self-Attention Networks?**, [[paper]](https://www.aclweb.org/anthology/2020.acl-main.269.pdf), [[bibtex]](/Bibtex/How%20Does%20Selective%20Mechanism%20Improve%20Self-Attention%20Networks.bib), sources: [[xwgeng/SSAN]](https://github.com/xwgeng/SSAN).
- [2021 ICLR] **Rao Blackwellizing the Straight-Through Gumbel-Softmax Gradient Estimator**, [[paper]](https://openreview.net/pdf?id=Mk6PZtgAgfq), [[bibtex]](/Bibtex/Rao%20Blackwellizing%20the%20Straight-Through%20Gumbel-Softmax%20Gradient%20Estimator.bib).

## Mutual Information and Contrastive Learning
- [2018 ICML] **Mutual Information Neural Estimation**, [[paper]](http://proceedings.mlr.press/v80/belghazi18a/belghazi18a.pdf), [[bibtex]](/Bibtex/Mutual%20Information%20Neural%20Estimation.bib), sources: [[MasanoriYamada/Mine_pytorch]](https://github.com/MasanoriYamada/Mine_pytorch), [[mzgubic/MINE]](https://github.com/mzgubic/MINE), [[gtegner/mine-pytorch]](https://github.com/gtegner/mine-pytorch).
- [2018 ArXiv] **Representation Learning with Contrastive Predictive Coding**, [[paper]](https://arxiv.org/pdf/1807.03748.pdf), [[bibtex]](/Bibtex/Representation%20Learning%20with%20Contrastive%20Predictive%20Coding.bib), sources: [[davidtellez/contrastive-predictive-coding]](https://github.com/davidtellez/contrastive-predictive-coding), [[flrngel/cpc-tensorflow]](https://github.com/flrngel/cpc-tensorflow), [[jefflai108/Contrastive-Predictive-Coding-PyTorch]](https://github.com/jefflai108/Contrastive-Predictive-Coding-PyTorch).
- [2019 ICLR] **Deep Graph Infomax**, [[paper]](https://openreview.net/pdf?id=rklz9iAcKQ), [[bibtex]](/Bibtex/Deep%20Graph%20Infomax.bib), sources: [[PetarV-/DGI]](https://github.com/PetarV-/DGI).
- [2019 ICLR] **Learning Deep Representations by Mutual Information Estimation and Maximization**, [[paper]](https://openreview.net/pdf?id=Bklr3j0cKX), [[bibtex]](/Bibtex/Learning%20Deep%20Representations%20by%20Mutual%20Information%20Estimation%20and%20Maximization.bib), sources: [[rdevon/DIM]](https://github.com/rdevon/DIM).
- [2019 NeurIPS] **Learning Representations by Maximizing Mutual Information Across Views**, [[paper]](https://papers.nips.cc/paper/2019/file/ddf354219aac374f1d40b7e760ee5bb7-Paper.pdf), [[bibtex]](/Bibtex/Learning%20Representations%20by%20Maximizing%20Mutual%20Information%20Across%20Views.bib), sources: [[Philip-Bachman/amdim-public]](https://github.com/Philip-Bachman/amdim-public).

## Earth Mover's Distance
- [2009 ICCV] **Fast and Robust Earth Moverâ€™s Distances**, [[paper]](https://www.cs.huji.ac.il/~werman/Papers/ICCV2009.pdf), [[bibtex]](/Bibtex/Fast%20and%20Robust%20Earth%20Movers%20Distances.bib), sources: [[wmayner/pyemd]](https://github.com/wmayner/pyemd), [[LeeKamentsky/pyemd]](https://github.com/LeeKamentsky/pyemd).
- [2015 ICML] **From Word Embeddings To Document Distances**, [[paper]](http://proceedings.mlr.press/v37/kusnerb15.pdf), [[bibtex]](/Bibtex/From%20Word%20Embeddings%20To%20Document%20Distances.bib), sources: [[mkusner/wmd]](https://github.com/mkusner/wmd), [[src-d/wmd-relax]](https://github.com/src-d/wmd-relax), [[stephenhky/PyWMD]](https://github.com/stephenhky/PyWMD).
- [2017 ICML] **Wasserstein Generative Adversarial Networks**, [[paper]](http://proceedings.mlr.press/v70/arjovsky17a/arjovsky17a.pdf), [[supplementary]](http://proceedings.mlr.press/v70/arjovsky17a/arjovsky17a-supp.pdf), [[arxiv]](https://arxiv.org/pdf/1701.07875.pdf), [[bibtex]](/Bibtex/Wasserstein%20Generative%20Adversarial%20Networks.bib), [[homepage]](http://proceedings.mlr.press/v70/arjovsky17a.html), [[explaination1]](https://zhuanlan.zhihu.com/p/25071913), [[explaination 2]](https://www.zhihu.com/question/52602529/answer/158727900), [[explaination3]](https://www.jiqizhixin.com/articles/2018-10-31-31), sources: [[kpandey008/wasserstein-gans]](https://github.com/kpandey008/wasserstein-gans), [[martinarjovsky/WassersteinGAN]](https://github.com/martinarjovsky/WassersteinGAN), [[luslab/scRNAseq-WGAN-GP]](https://github.com/luslab/scRNAseq-WGAN-GP).
- [2019 ACL] **Sentence Movers Similarity: Automatic Evaluation for Multi-Sentence Texts**, [[paper]](https://www.aclweb.org/anthology/P19-1264v2.pdf), [[bibtex]](https://www.aclweb.org/anthology/P19-1264.bib), sources: [[eaclark07/sms]](https://github.com/eaclark07/sms).
- [2020 CVPR] **DeepEMD: Few-Shot Image Classification with Differentiable Earth Movers**, [[paper]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_DeepEMD_Few-Shot_Image_Classification_With_Differentiable_Earth_Movers_Distance_and_CVPR_2020_paper.pdf), [[bibtex]](/Bibtex/DeepEMD.bib), sources: [[icoz69/DeepEMD]](https://github.com/icoz69/DeepEMD).

## Others
- [2013 ICML] **Deep Canonical Correlation Analysis**, [[paper]](http://proceedings.mlr.press/v28/andrew13.pdf), [[bibtex]](/Bibtex/Deep%20Canonical%20Correlation%20Analysis.bib), sources: [[VahidooX/DeepCCA]](https://github.com/VahidooX/DeepCCA), [[DTaoo/DCCA]](https://github.com/DTaoo/DCCA), [[msamribeiro/deep-cca]](https://github.com/msamribeiro/deep-cca), [[wangxu-scu/DeepCCA]](https://github.com/wangxu-scu/DeepCCA).
- [2014 EACL] **CCA: Improving Vector Space Word Representations Using Multilingual Correlation**, [[paper]](https://www.aclweb.org/anthology/E14-1049.pdf), [[bibtex]](https://www.aclweb.org/anthology/E14-1049.bib).
- [2017 TIML] **Efficient Methods and Hardware for Deep Learning**, [[Ph.D Thesis]](https://stacks.stanford.edu/file/druid:qf934gh3708/EFFICIENT%20METHODS%20AND%20HARDWARE%20FOR%20DEEP%20LEARNING-augmented.pdf), [[bibtex]](/Bibtex/Efficient%20Methods%20and%20Hardware%20for%20Deep%20Learning.bib), [[Song Han's homepage]](https://mtlsites.mit.edu/songhan/), [[slides]](https://platformlab.stanford.edu/Seminar%20Talks/retreat-2017/Song%20Han.pdf).
- [2017 NIPS] **SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability**, [[paper]](https://papers.nips.cc/paper/7188-svcca-singular-vector-canonical-correlation-analysis-for-deep-learning-dynamics-and-interpretability.pdf), [[bibtex]](/Bibtex/SVCCA.bib), sources: [[google/svcca]](https://github.com/google/svcca).
- [2017 ArXiv] **One Model To Learn Them All**, [[paper]](https://arxiv.org/abs/1706.05137.pdf), [[blog]](https://blog.acolyer.org/2018/01/12/one-model-to-learn-them-all/), [[bibtex]](/Bibtex/One%20Model%20To%20Learn%20Them%20All.bib).
- [2017 ArXiv] **An Overview of Multi-Task Learning in Deep Neural Networks**, [[paper]](https://arxiv.org/pdf/1706.05098.pdf), [[bibtex]](/Bibtex/An%20Overview%20of%20Multi-Task%20Learning%20in%20Deep%20Neural%20Networks.bib).
- [2017 PNAS] **Robust Continuous Clustering**, [[paper]](http://vladlen.info/papers/RCC-with-supplement.pdf), [[bibtex]](/Bibtex/Robust%20Continuous%20Clustering.bib), sources: [[sohilas/robust-continuous-clustering]](https://bitbucket.org/sohilas/robust-continuous-clustering/overview), [[yhenon/pyrcc]](https://github.com/yhenon/pyrcc), [[shahsohil/DCC]](https://github.com/shahsohil/DCC).
- [2018 ArXiv] **Tunneling Neural Perception and Logic Reasoning through Abductive Learning**, [[paper]](https://arxiv.org/pdf/1802.01173.pdf), [[bibtex]](/Bibtex/Tunneling%20Neural%20Perception%20and%20Logic%20Reasoning%20through%20Abductive%20Learning.bib)
- [2018 AAAI] **Reliable Multi-View Clustering**, [[paper]](https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16245/16686), [[bibtex]](/Bibtex/Reliable%20Multi-View%20Clustering.bib).
- [2018 AAAI] **SC2Net: Sparse LSTMs for Sparse Coding**, [[paper]](https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16822/16773), [[bibtex]](/Bibtex/SC2Net%20-%20Sparse%20LSTMs%20for%20Sparse%20Coding.bib), sources: [[joeyzhouty/sc2net]](https://github.com/joeyzhouty/sc2net).
- [2019 ArXiv] **Implicit Generation and Generalization in Energy-Based Models**, [[paper]](https://arxiv.org/pdf/1903.08689.pdf), [[bibtex]](/Bibtex/Implicit%20Generation%20and%20Generalization%20in%20Energy-Based%20Models.bib), [[homepage]](https://sites.google.com/view/igebm), [[blog]](https://openai.com/blog/energy-based-models/), [[ext. readings]](http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf), sources: [[openai/ebm_code_release]](https://github.com/openai/ebm_code_release), [[rosinality/igebm-pytorch]](https://github.com/rosinality/igebm-pytorch).
- [2019 SIGIR] **Finding Camouflaged Needle in a Haystack? Pornographic Products Detection via Berrypicking Tree Model**, [[paper]](/Documents/Papers/Finding%20Camouflaged%20Needle%20in%20a%20Haystack%20Pornographic%20Products%20Detection%20via%20Berrypicking%20Tree%20Model.pdf), [[bibtex]](/Bibtex/Finding%20Camouflaged%20Needle%20in%20a%20Haystack%20Pornographic%20Products%20Detection%20via%20Berrypicking%20Tree%20Model.bib), [[slides]](https://sigir.org/sigir2019/slides/10.1145-3331184.3331197.pdf), sources: [[GuoxiuHe/BIRD]](https://github.com/GuoxiuHe/BIRD).
- [2019 ICML] **COMIC: Multi-view Clustering Without Parameter Selection**, [[paper]](http://proceedings.mlr.press/v97/peng19a/peng19a.pdf), [[bibtex]](/Bibtex/COMIC%20-%20Multi-view%20Clustering%20Without%20Parameter%20Selection.bib).
- [2019 NeurIPS] **PyTorch: An Imperative Style, High-Performance Deep Learning Library**, [[paper]](https://papers.nips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf), [[bibtex]](/Bibtex/PyTorch%20-%20An%20Imperative%20Style%20High-Performance%20Deep%20Learning%20Library.bib).
- [2019 NeurIPS] **Addressing Failure Prediction by Learning Model Confidence**, [[paper]](https://papers.nips.cc/paper/2019/file/757f843a169cc678064d9530d12a1881-Paper.pdf), [[bibtex]](/Bibtex/Addressing%20Failure%20Prediction%20by%20Learning%20Model%20Confidence.bib), sources: [[valeoai/ConfidNet]](https://github.com/valeoai/ConfidNet).
- [2021 ArXiv] **Attention is not all you need: pure attention loses rank doubly exponentially with depth**, [[paper]](https://arxiv.org/pdf/2103.03404.pdf), [[bibtex]](/Bibtex/Attention%20is%20not%20all%20you%20need%20-%20pure%20attention%20loses%20rank%20doubly%20exponentially%20with%20depth.bib), sources: [[twistedcubic/attention-rank-collapse]](https://github.com/twistedcubic/attention-rank-collapse).
- [2021 ICLR] **Trusted Multi-View Classification**, [[paper]](https://openreview.net/pdf?id=OOsR8BzCnl5), [[bibtex]](/Bibtex/Trusted%20Multi-View%20Classification.bib), sources: [[hanmenghan/TMC]](https://github.com/hanmenghan/TMC).