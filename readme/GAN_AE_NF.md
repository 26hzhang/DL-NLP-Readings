# Generative Adversarial Network, Autoencoder and Normalizing Flow

## Generative Adversarial Network (GAN)
- Awesome-GANs papers and codes: [[kozistr/Awesome-GANs]](https://github.com/kozistr/Awesome-GANs), [[hollobit/All-About-the-GAN]](https://github.com/hollobit/All-About-the-GAN).
- [2014 NIPS] **Generative Adversarial Nets**, [[paper]](https://arxiv.org/abs/1406.2661), [[bibtex]](/Bibtex/Generative%20Adversarial%20Nets.bib), sources: [[goodfeli/adversarial]](https://github.com/goodfeli/adversarial), [[aymericdamien/TensorFlow-Examples]](https://github.com/aymericdamien/TensorFlow-Examples).
- [2016 ICLR] **Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks**, [[paper]](https://arxiv.org/abs/1511.06434), [[bibtex]](/Bibtex/Unsupervised%20Representation%20Learning%20with%20Deep%20Convolutional%20Generative%20Adversarial%20Networks.bib) sources: [[Newmu/dcgan_code]](https://github.com/Newmu/dcgan_code).
- [2017 ICLR] **Towards Principled Methods for Training Generative Adversarial Networks**, [[paper]](https://openreview.net/pdf?id=Hk4_qw5xe), [[bibtex]](/Bibtex/Towards%20Principled%20Methods%20for%20Training%20Generative%20Adversarial%20Networks.bib).
- [2017 ICML] **Wasserstein Generative Adversarial Networks**, [[paper]](http://proceedings.mlr.press/v70/arjovsky17a/arjovsky17a.pdf), [[supplementary]](http://proceedings.mlr.press/v70/arjovsky17a/arjovsky17a-supp.pdf), [[arxiv]](https://arxiv.org/pdf/1701.07875.pdf), [[bibtex]](/Bibtex/Wasserstein%20Generative%20Adversarial%20Networks.bib), [[homepage]](http://proceedings.mlr.press/v70/arjovsky17a.html), [[explain1]](https://zhuanlan.zhihu.com/p/25071913), [[explain2]](https://www.zhihu.com/question/52602529/answer/158727900), [[explain3]](https://www.jiqizhixin.com/articles/2018-10-31-31), [[explain4]](https://www.cnblogs.com/king-lps/p/8480267.html), sources: [[kpandey008/wasserstein-gans]](https://github.com/kpandey008/wasserstein-gans), [[martinarjovsky/WassersteinGAN]](https://github.com/martinarjovsky/WassersteinGAN), [[luslab/scRNAseq-WGAN-GP]](https://github.com/luslab/scRNAseq-WGAN-GP).
- [2017 AAAI] **SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient**, [[paper]](https://arxiv.org/abs/1609.05473), [[bibtex]](/Bibtex/SeqGAN.bib), sources:[[LantaoYu/SeqGAN]](https://github.com/LantaoYu/SeqGAN).
- [2017 ICCV] **CycleGAN: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks**, [[paper]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhu_Unpaired_Image-To-Image_Translation_ICCV_2017_paper.pdf), [[bibtex]](/Bibtex/Unpaired%20Image-to-Image%20Translation%20using%20Cycle-Consistent%20Adversarial%20Networks.bib), [[homepage]](https://junyanz.github.io/CycleGAN/), sources: [[junyanz/pytorch-CycleGAN-and-pix2pix]](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix), [[junyanz/CycleGAN]](https://github.com/junyanz/CycleGAN), [[xhujoy/CycleGAN-tensorflow]](https://github.com/xhujoy/CycleGAN-tensorflow).
- [2018 ICLR] **CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training**, [[paper]](https://openreview.net/pdf?id=BJE-4xW0W), [[bibtex]](/Bibtex/CausalGAN%20-%20Learning%20Causal%20Implicit%20Generative%20Models%20with%20Adversarial%20Training.bib), sources: [[mkocaoglu/CausalGAN]](https://github.com/mkocaoglu/CausalGAN).
- [2018 ICLR] **Progressive Growing of GANs for Improved Quality, Stability, and Variation**, [[paper]](https://openreview.net/pdf?id=Hk99zCeAb), [[bibtex]](/Bibtex/Progressive%20Growing%20of%20GANs%20for%20Improved%20Quality%20Stability%20and%20Variation.bib), sources: [[tkarras/progressive_growing_of_gans]](https://github.com/tkarras/progressive_growing_of_gans).
- [2018 ArXiv] **A Style-Based Generator Architecture for Generative Adversarial Networks**, [[paper]](https://arxiv.org/pdf/1812.04948.pdf), [[bibtex]](/Bibtex/A%20Style-Based%20Generator%20Architecture%20for%20Generative%20Adversarial%20Networks.bib), [[blog]](https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431), sources: [[NVlabs/stylegan]](https://github.com/NVlabs/stylegan), [[Puzer/stylegan-encoder]](https://github.com/Puzer/stylegan-encoder).
- [2018 ArXiv] **XGAN: Unsupervised Image-to-Image Translation for Many-to-Many Mappings**, [[paper]](https://arxiv.org/pdf/1711.05139.pdf), [[bibtex]](/Bibtex/XGAN%20-%20Unsupervised%20Image-to-Image%20Translation%20for%20Many-to-Many%20Mappings.bib), [[Cartoon Dataset]](https://google.github.io/cartoonset/index.html).
- [2018 ICLR] **Spectral Normalization for Generative Adversarial Networks**, [[paper]](https://openreview.net/pdf?id=B1QRgziT-), [[bibtex]](/Bibtex/Spectral%20Normalization%20for%20Generative%20Adversarial%20Networks.bib), sources: [[pfnet-research/sngan_projection]](https://github.com/pfnet-research/sngan_projection).
- [2019 ICLR] **On Computation and Generalization of Generative Adversarial Networks under Spectrum Control**, [[paper]](https://openreview.net/pdf?id=rJNH6sAqY7), [[bibtex]](/Bibtex/On%20Computation%20and%20Generalization%20of%20Generative%20Adversarial%20Networks%20under%20Spectrum%20Control.bib), sources: [[HMJiangGatech/spectral-control-GAN]](https://github.com/HMJiangGatech/spectral-control-GAN).

## Autoencoder
- [CS294A] **Sparse Autoencoder**, [[lecture notes]](/Papers/General/Autoencoder/Sparse%20Autoencoder.pdf).
- [2014 ICLR] **k-Sparse Autoencoders**, [[paper]](https://arxiv.org/pdf/1312.5663.pdf), [[bibtex]](/Bibtex/k-Sparse%20Autoencoders.bib), sources: [[arashsaber/Sparse-Auto-Encoder]](https://github.com/arashsaber/Sparse-Auto-Encoder), [[snooky23/K-Sparse-AutoEncoder]](https://github.com/snooky23/K-Sparse-AutoEncoder).
- [2015] **Adversarial Autoencoders**, [[paper]](https://arxiv.org/pdf/1511.05644.pdf), [[slides]](https://duvenaud.github.io/learn-discrete/slides/AdversarialAutoencoders.pdf), [[bibtex]](/Bibtex/Adversarial%20Autoencoders.bib), sources: [[conan7882/adversarial-autoencoders]](https://github.com/conan7882/adversarial-autoencoders), [[neale/Adversarial-Autoencoder]](https://github.com/neale/Adversarial-Autoencoder).
- [2020 ICLR] **From Variational to Deterministic Autoencoders**, [[paper]](https://openreview.net/pdf?id=S1g7tpEYDS), [[bibtex]](/Bibtex/From%20Variational%20to%20Deterministic%20Autoencoders.bib), sources: [[ParthaEth/Regularized_autoencoders-RAE-]](https://github.com/ParthaEth/Regularized_autoencoders-RAE-).

## Normalizing Flow
- [2015 ICLR] **NICE: Non-linear Independent Components Estimation**, [[paper]](https://arxiv.org/pdf/1410.8516.pdf), [[bibtex]](/Bibtex/NICE.bib), sources: [[paultsw/nice_pytorch]](https://github.com/paultsw/nice_pytorch), [[DakshIdnani/pytorch-nice]](https://github.com/DakshIdnani/pytorch-nice), [[laurent-dinh/nice]](https://github.com/laurent-dinh/nice).
- [2017 ICLR] **Density Estimation using Real NVP**, [[paper]](https://openreview.net/pdf?id=HkpbnH9lx), [[bibtex]](/Bibtex/Density%20Estimation%20using%20Real%20NVP.bib), sources: [[chrischute/real-nvp]](https://github.com/chrischute/real-nvp), [[xqding/RealNVP]](https://github.com/xqding/RealNVP).
- [2017 NeurIPS] **The Reversible Residual Network: Backpropagation Without Storing Activations**, [[paper]](https://papers.nips.cc/paper/2017/file/f9be311e65d81a9ad8150a60844bb94c-Paper.pdf), [[bibtex]](/Bibtex/The%20Reversible%20Residual%20Network.bib), sources: [[renmengye/revnet-public]](https://github.com/renmengye/revnet-public).
- [2018 NeurIPS] **Glow: Generative Flow with Invertible 1Ã—1 Convolutions**, [[paper]](https://papers.nips.cc/paper/2018/file/d139db6a236200b21cc7f752979132d0-Paper.pdf), [[bibtex]](/Bibtex/Glow.bib), sources: [[openai/glow]](https://github.com/openai/glow), [[chaiyujin/glow-pytorch]](https://github.com/chaiyujin/glow-pytorch), [[rosinality/glow-pytorch]](https://github.com/rosinality/glow-pytorch), [[samuelmat19/GLOW-tf2]](https://github.com/samuelmat19/GLOW-tf2).
- [2020 TPAMI] **Normalizing Flows: An Introduction and Review of Current Methods**, [[paper]](https://arxiv.org/pdf/1908.09257v4.pdf), [[ArXiv v1]](https://arxiv.org/pdf/1908.09257v1.pdf), [[bibtex]](/Bibtex/Normalizing%20Flows.bib).